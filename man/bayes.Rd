% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-bayes.R
\name{bayes}
\alias{bayes}
\alias{bayes_beta_c}
\alias{bayes_beta_d}
\alias{bayes_dirichlet_d}
\alias{bayes_dirichlet_c}
\title{Bayesian Inference Cognitive Model}
\usage{
bayes_beta_c(
  formula,
  data,
  fix = NULL,
  format = c("raw", "count", "cumulative"),
  prior_sum = NULL,
  ...
)

bayes_beta_d(formula, data, fix = NULL, format = NULL, prior_sum = NULL, ...)

bayes_dirichlet_d(
  formula,
  data,
  fix = NULL,
  format = NULL,
  prior_sum = NULL,
  ...
)

bayes_dirichlet_c(
  formula,
  data,
  fix = NULL,
  format = NULL,
  prior_sum = NULL,
  ...
)

bayes(
  formula,
  data = data.frame(),
  fix = list(),
  format = c("raw", "count", "cumulative"),
  type = NULL,
  discount = 0L,
  options = list(),
  prior_sum = NULL,
  ...
)
}
\arguments{
\item{formula}{A \link[stats:formula]{formula}, the variables in \code{data} to be modeled. For example, \code{y ~ x1 + x2} models response y as function of one stimulus with features x1, x2.}

\item{data}{A data frame, the data to be modeled.}

\item{fix}{(optional) A list with parameter-value pairs of fixed parameters. If missing all free parameters are estimated. If set to \code{"start"} all parameters are fixed to their start values. Model parameter names depend on \code{formula} and can be \emph{\code{delta}, \code{x1}, \code{x2}} (see details - model parameters).
\itemize{
\item \code{list(x1 = 3.09)} sets parameter \emph{\code{x1}} equal to 3.09.
\item \code{list(x1 = "x2")} sets parameter \emph{\code{x1}} equal to parameter \emph{\code{x2}} (estimates \emph{\code{x2}}).
\item \code{list(x2 = "x1", x1 = 3.09)} sets parameter \emph{\code{x2}} equal to parameter \emph{\code{x1}} and sets \emph{\code{x1}} equal to 3.09 (estimates none of the two).
\item \code{list(x1 = NA)} omits the parameter \emph{\code{x1}}, if possible.
\item \code{"start"} sets all parameters equal to their initial values (estimates none). Useful for building a first test model.
}}

\item{format}{(optional) A string, the format the data to be modeled, can be abbreviated, default is \code{"raw"}; allowed values:
\itemize{
\item \code{"raw"} means that the data are trial-by-trial binary occurrence indicators: 1, 0, 1, ... means the event happened in trial with a value of 1.
\item \code{"cumulative"} means the data are trial-by-trial cumulative counts of events: 0, 1, 1, 2, ... counts how often the event happened up to the trial.
\item \code{"count"} means the data are total events counts, ignoring the trial-by-trial order of events: 2, 10, ... means the event happened 2 times, then (starting from zero!) it happened 10 times.
}}

\item{prior_sum}{(optional) A number; the prior hyperparameter will be constrained to sum to this number; defaults to the number of prior parameters; if \code{prior_sum = NA} no sum constraint is placed.}

\item{...}{other arguments, ignored.}

\item{type}{(optional) A string, the type of inference, \code{"beta-binomial"} or \code{"dirichlet-multinomial"}. Can be abbreviated. Will be inferred, if missing.}

\item{discount}{A number, how many initial trials to not use during parameter fitting.}

\item{options}{(optional) A list, list entries change the modeling procedure. For example, \code{list(lb = c(k=0))} changes the lower bound of parameter \emph{k} to 0, or \code{list(fit_measure = "mse")} changes the goodness of fit measure in parameter estimation to mean-squared error,  for all options, see \link{cm_options}.}
}
\value{
Returns a cognitive model object, which is an object of class \href{Cm}{cm}. A model, that has been assigned to \code{m}, can be summarized with \code{summary(m)} or \code{anova(m)}. The parameter space can be viewed using \verb{pa. rspace(m)}, constraints can be viewed using \code{constraints(m)}.
}
\description{
\code{bayes()} fits a Bayesian cognitive model, updating beliefs about the probability of discrete event outcomes based on the frequencies of outcomes.
\itemize{
\item \code{bayes_beta_c()} fits a model for 2 outcomes (beta-binomial) for continuous responses
\item \code{bayes_beta_d()} fits a model for 2 outcomes (beta-binomial) for discrete responses
\item \code{bayes_dirichlet_c()} fits a model for \emph{n > 2} outcomes (dirichlet-categorical/multinomial) for continuous responses
\item \code{bayes_dirichlet_d()} fits a model for \emph{n > 2} outcomes (dirichlet-categorical/multinomial) for discrete responses
}
}
\details{
The model models -- as response -- the belief about the occurrence of the first event in the \code{formula} as follows:
\itemize{
\item \code{y ~ x1} models the beliefe about event \strong{x1 occurring} versus it not occurring.
\item \code{y ~ x1 + x2} models beliefs about \strong{x1 versus x2} occurring.
\item \code{y ~ x1 + x2 + x3} models beliefs about x1, x2, and x3 occurring.
}
\subsection{Model Parameters}{

The model has \emph{n + 1} (\emph{n} = number of events) free parameters, which are:
\itemize{
\item \code{delta} is the learning rate, it weights the observation during learning, value < 1 causes conservatism, > 1 causes liberal learning, and 1 is optimal Bayesian.
\item \verb{x1, x2} (dynamic names) are the prior parameter, their names correspond to the right side of \code{formula}. Also known as the hyperparameter of the prior belief distribution before trial 1. If they are constrainted to sum to \emph{n} and \emph{n} - 1 parameter are estimated.
\item In \code{bayes_beta_d()} or \code{bayes_dirichlet_d()}: If \code{choicerule = "softmax"}: \emph{\strong{\code{tau}}}  is the temperature or choice softness, higher values cause more equiprobable choices. If \code{choicerule = "epsilon"}: \emph{\strong{\code{eps}}} is the error proportion, higher values cause more errors from maximizing.
}
}
}
\examples{
D <- data.frame(
  a = c(0,0,1,1,1),              # event A, e.g. coin toss "heads"
  b = c(1,1,0,0,0),              # event B, complement of A
  y = c(0.5,0.3,0.2,0.3,0.5))    # participants' beliefs about A

M <- bayes_beta_c(
     formula = y ~ a + b,
     data = D)   # fit all parameters
predict(M)                        # predict posterior means
summary(M)                        # summarize model
parspace(M)                       # view parameter space
anova(M)                          # anova-like table
logLik(M)                         # loglikelihood
MSE(M)                            # mean-squared error   


# Predictions ----------------------------------------------
predict(M, type = "mean")                  # posterior mean
predict(M, type = "max")                   # maximum posterior
predict(M, type = "sd")                    # posterior SD
predict(M, type = "posteriorpar")          # posterior hyper-par.
predict(M, type = "draws", ndraws = 3)     #  --"--  3 draws


# Fix parameter ---------------------------------------------
bayes_beta_c(~a+b, D, list(delta=1, priorpar=c(1, 1)))  # delta=1, uniform prior
bayes_beta_c(~a+b, D, list(delta=1, a=1, b=1))          # -- (same) --
bayes_beta_c(~a+b, D, fix = "start")                    # fix to start values


# Parameter fitting ----------------------------------------
# Use a response variable, y, to which we fit parameter
bayes(y ~ a + b, D, fix = "start")              # "start" fixes all par., fit none 
bayes(y ~ a + b, D, fix = list(delta=1))         # fix delta, fit priors 
bayes(y ~ a + b, D, fix = list(a=1, b=1))        # fix priors, fit delta 
bayes(y ~ a + b, D, fix = list(delta=1, a=1))    # fix delta & prior on "a"
bayes(y ~ a + b, D, list(delta=1, b=1))          # fix delta & prior on "b"


### Parameter meanings
# ---------------------------------------
# delta parameter: the learning rate or evidence weight
bayes(y ~ a + b, D, c(delta = 0))             # 0   -> no learning
bayes(y ~ a + b, D, c(delta = 0.1))           # 0.1 -> slow learning
bayes(y ~ a + b, D, c(delta = 9))             # 9   -> fast learning
bayes(y ~ a + b, D, c(a=1.5, b=0.5))                # prior: a more likely
bayes(y ~ a + b, D, list(priorpar=c(1.5, 0.5)))     # -- (same) --
bayes(y ~ a + b, D, c(a = 0.1, b=1.9))              # prior: b more likely
bayes(y ~ a + b, D, list(priorpar = c(0.1, 1.9)))   # -- (same) --
}
\references{
{Griffiths, T. L., & Yuille, A. (2008). Technical Introduction: A primer on probabilistic inference. In N. Chater & M. Oaksford (Eds.), \emph{The Probabilistic Mind: Prospects for Bayesian Cognitive Science (pp. 1 - 2)}. Oxford University Press. \url{https://doi.org/10.1093/acprof:oso/9780199216093.003.0002}}

{Tauber, S., Navarro, D. J., Perfors, A., & Steyvers, M. (2017). Bayesian models of cognition revisited: Setting optimality aside and letting data drive psychological theory. \emph{Psychological Review, 124(4)}, 410 - 441. \url{http://dx.doi.org/10.1037/rev0000052}}
}
\seealso{
Other cognitive models: 
\code{\link{baseline_const_c}()},
\code{\link{choicerules}},
\code{\link{cpt}},
\code{\link{ebm}()},
\code{\link{hm1988}()},
\code{\link{shift}()},
\code{\link{shortfall}},
\code{\link{threshold}()},
\code{\link{utility}}
}
\author{
Markus Steiner

Jana B. Jarecki, \email{jj@janajarecki.com}
}
\concept{cognitive models}
