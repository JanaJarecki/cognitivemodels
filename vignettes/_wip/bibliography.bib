Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Benureau2018,
abstract = {Scientific code is different from production software. Scientific code, by producing results that are then analyzed and interpreted, participates in the elaboration of scientific conclusions. This imposes specific constraints on the code that are often overlooked in practice. We articulate, with a small example, five characteristics that a scientific code in computational science should possess: re-runnable, repeatable, reproducible, reusable, and replicable. The code should be executable (re-runnable) and produce the same result more than once (repeatable); it should allow an investigator to reobtain the published results (reproducible) while being easy to use, understand and modify (reusable), and it should act as an available reference for any ambiguity in the algorithmic descriptions of the article (replicable).},
archivePrefix = {arXiv},
arxivId = {1708.08205},
author = {Benureau, Fabien C Y and Rougier, Nicolas P},
doi = {10.3389/fninf.2017.00069},
eprint = {1708.08205},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Benureau, Rougier{\_}2018{\_}Re-run, Repeat, Reproduce, Reuse, Replicate Transforming Code into Scientific Contributions.pdf:pdf},
issn = {16625196},
journal = {Frontiers in Neuroinformatics},
keywords = {Best practices,Computational science,Replicability,Reproducibility of results,Reproducible research,Reproducible science,Software development},
number = {January},
pages = {1--8},
title = {{Re-run, Repeat, Reproduce, Reuse, Replicate: Transforming Code into Scientific Contributions}},
volume = {11},
year = {2018}
}
@misc{R,
address = {Vienna, Austria},
author = {{R Core Team}},
keywords = {R,methods,program,statistical environment},
mendeley-tags = {R,methods,program,statistical environment},
publisher = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org/},
year = {2019}
}
@article{Navarro2019,
author = {Navarro, Danielle J},
doi = {10.1007/s42113-018-0019-z},
journal = {Computational Brain {\&} Behavior},
keywords = {Model selection,Science,Statistics,be an evergreen topic,competing,each instantiated as parameterised,given two or more,in,mathematical psychology,model selection,model selection seems to,science,statistics,theories about the world},
pages = {28--34},
title = {{Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection}},
volume = {2},
year = {2019}
}
@article{Juslin2003,
abstract = {Categorization and multiple-cue judgment are similar tasks, but the influential models in the two areas are different in terms of the computations, processes, and neural substrates that they imply. In categorization, exemplar memory is often emphasized, whereas multiple-cue judgment generally is interpreted in terms of integration of cues that have been abstracted in training. In 3 experiments the authors investigated whether these conclusions derive from genuine differences in the processes or are accidental to the different research methods. The results revealed large individual differences and a shift from exemplar memory to cue abstraction when the criterion is changed from a binary to a continuous variable, especially for a probabilistic criterion. People appear to switch between qualitatively distinct processes in the 2 tasks.},
annote = {From Duplicate 1 (Exemplar effects in categorization and multiple-cue judgment. - Juslin, Peter; Olsson, Henrik; Olsson, Anna-Carin)

Probabilistic + deterministic judgment (=cotinuous value) task. Prob only slightly worse than det, 200 trials only.},
author = {Juslin, Peter and Olsson, Henrik and Olsson, Anna-Carin},
doi = {10.1037/0096-3445.132.1.133},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Juslin, Olsson, Olsson{\_}2003{\_}Exemplar effects in categorization and multiple-cue judgment.pdf:pdf},
isbn = {0096-3445$\backslash$n1939-2222},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {exemplar model,judgment,memory},
mendeley-tags = {exemplar model,judgment,memory},
number = {1},
pages = {133--156},
pmid = {12656301},
title = {{Exemplar effects in categorization and multiple-cue judgment.}},
volume = {132},
year = {2003}
}
@phdthesis{Andraszewicz2014,
abstract = {Risky economic decisions play an important role in everyone's life. This dissertation presents mathematical approaches to the analysis of these decisions. It discusses how statistical measures can describe properties of choice options, and how these properties can be used to describe the decision context. Also, this dissertation includes a practical tutorial on a Bayesian approach to the hierarchical regression analysis in management science. Therefore, the combined dissertation presents mathematical and statistical tools in, and for better research of, decision making under risk. The first manuscript proposes standardized covariance, a measure that can quantitatively describe the strength of the association and similarity between choice options' outcomes. The standardized covariance can also describe how risky one option is with respect to another. It can influence predictions of choice models. The second manuscript shows experimentally how association measured with the standardized covariance can influence people's choices. The third manuscript proposes applying the expected shortfall of an option's outcomes as a measure of risk in the standard risk-value models. In an experiment, the risk-value shortfall model successfully predicted people's preference for options with higher expected value, lower variance and more positively skewed distributions of outcomes, and outperformed competing models. The fourth manuscript proposes a new version of a reinforcement learning model, which can be applied in a social context. The proposed model can account for the behavior of other people competing for a common pool resource. As experimentally tested, the model could successfully predict human behavior and correlated with the brain activity measured with an fMRI method. The last manuscript outlines advantages of using Bayes factors instead of p-values for interpretation of results from hierarchical regression analysis. As the results in the manuscript show, the Bayesian approach and the standard null-hypothesis statistical testing can lead to different conclusions},
author = {Andraszewicz, Sandra},
doi = {10.5451/unibas-006268585},
keywords = {risk,risk-taking,shortfall},
mendeley-tags = {risk,risk-taking,shortfall},
title = {{Quntitative [i.e. Quantitative] analysis of risky decision making in economic environments}},
year = {2014}
}
@article{Singmann2013,
abstract = {We introduce MPTinR, a software package developed for the analysis of multinomial processing tree (MPT) models. MPT models represent a prominent class of cognitive measurement models for categorical data with applications in a wide variety of fields. MPTinR is the first software for the analysis of MPT models in the statistical programming language R, providing a modeling framework that is more flexible than standalone software packages. MPTinR also introduces important features such as (1) the ability to calculate the Fisher information approximation measure of model complexity for MPT models, (2) the ability to fit models for categorical data outside the MPT model class, such as signal detection models, (3) a function for model selection across a set of nested and nonnested candidate models (using several model selection indices), and (4) multicore fitting. MPTinR is available from the Comprehensive R Archive Network at http://cran.r-project.org/web/packages/MPTinR/ .},
author = {Singmann, Henrik and Kellen, David},
doi = {10.3758/s13428-012-0259-0},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Singmann, Kellen{\_}2013{\_}MPTinR Analysis of multinomial processing tree models in R.pdf:pdf},
isbn = {1342801202},
issn = {1554-3528},
journal = {Behavior Research Methods},
keywords = {Algorithms,Decision Trees,FIA,Humans,MPTinR,Models,Programming Languages,Psychological,R package,Recognition (Psychology),Software,fisher information,methods,multinomial processing tree},
mendeley-tags = {FIA,MPTinR,R package,fisher information,methods,multinomial processing tree},
number = {2},
pages = {560--75},
pmid = {23344733},
title = {{MPTinR: Analysis of multinomial processing tree models in R.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23344733},
volume = {45},
year = {2013}
}
@article{Nosofsky1989,
abstract = {Further tests were provided of an exemplar-similarity model for relating the identification and categorization of separable-dimension stimuli (Nosofsky, 1986). On the basis of confusion errors in an identification paradigm, a multidimensional scaling (MDS) solution was derived for a set of 16 separable-dimension stimuli. This MDS solution was then used in conjunction with the exemplar-similarity model to accurately predict performance in four separate categorization paradigms with the same stimuli. A key to achieving the accurate quantitative fits was the assumption that a selective attention process systematically modifies similarities among exemplars across different category structures. The tests reported go well beyond earlier ones (Nosofsky, 1986) in demonstrating the generalizability and utility of the theoretical approach. Implications of the results for alternative quantitative models of classification performance, including Ashby and Perrin's (1988) general recognition theory, were also considered.},
annote = {From Duplicate 1 (Further tests of an exemplar-similarity approach to relating identification and categorization - Nosofsky, Robert M)

metric = 1.8 (r = 1.8)
decay = gaussian = 2 (p=2) or q = 2
b1 = bias for class1 (lower class, binary: 0)
w1 = weight gien to angle

Log likelihood formula used is in notes (p 289)

From Duplicate 2 (Further tests of an exemplar-similarity approach to relating identification and categorization - Nosofsky, Robert M.)

w1 = angle},
author = {Nosofsky, Robert M.},
doi = {10.3758/BF03204942},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Nosofsky{\_}1989{\_}Further tests of an exemplar-similarity approach to relating identification and categorization.pdf:pdf},
isbn = {0031-5117 (Print)$\backslash$r0031-5117 (Linking)},
issn = {00315117},
journal = {Perception {\&} Psychophysics},
keywords = {categorization,exemplar model},
mendeley-tags = {categorization,exemplar model},
number = {4},
pages = {279--290},
pmid = {2710628},
title = {{Further tests of an exemplar-similarity approach to relating identification and categorization}},
volume = {45},
year = {1989}
}
@article{Schwarz1978,
abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
author = {Schwarz, Gideon},
doi = {10.1214/aos/1176344136},
isbn = {0780394224},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {BIC,Bayes information criterion,N},
mendeley-tags = {BIC,Bayes information criterion,N},
number = {2},
pages = {461--464},
pmid = {2958889},
title = {{Estimating the dimension of a model}},
url = {http://projecteuclid.org/euclid.aos/1176344136},
volume = {6},
year = {1978}
}
@article{Wagenmakers2004,
abstract = {The Akaike information criterion (AIC; Akaike, 1973) is a popular method for comparing the adequacy ofmul- tiple, possibly nonnested models. Current practice in cog- nitive psychology is to accept a single model on the basis of only the “raw” AIC values, making it difficult to un- ambiguously interpret the observed AIC differences in terms ofa continuous measure such as probability. Here we demonstrate that AIC values can be easily transformed to so-called Akaike weights (e.g., Akaike, 1978, 1979; Boz- dogan, 1987; Burnham {\&} Anderson, 2002), which can be directly interpreted as conditional probabilities for each model. We show by example how these Akaike weights can greatly facilitate the interpretation of the results of AIC model comparison procedures.},
author = {Wagenmakers, Eric-jan and Farrell, Simon},
doi = {10.3758/BF03206482},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Wagenmakers, Farrell{\_}2004{\_}AIC model selection using Akaike weights.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin {\&} Review},
keywords = {AIC,AIC weight,akaike weight,methods,model selection},
mendeley-tags = {AIC,AIC weight,akaike weight,methods,model selection},
month = {feb},
number = {1},
pages = {192--196},
title = {{AIC model selection using Akaike weights}},
url = {http://www.springerlink.com/index/10.3758/BF03206482},
volume = {11},
year = {2004}
}
@article{Medin1978,
abstract = {Most theories dealing with ill-defined concepts assume that performance is based on category level information or a mixture of category level and specific item information. A context theory of classification is described in which judgments are assumed to derive exclusively from stored exemplar information. The main idea is that a probe item acts as a retrieval cue to access information associated with stimuli similar to the probe. The predictions of the context theory are contrasted with those of a class of theories (including prototype theory) that assume that the information entering into judgments can be derived from an additive combination of information from component cue dimensions. Across 4 experiments with 128 paid Ss, using both geometric forms and schematic faces as stimuli, the context theory consistently gave a better account of the data. The relation of context theory to other theories and phenomena associated with ill-defined concepts is discussed in detail.},
author = {Medin, Douglas L and Schaffer, Marguerite M},
doi = {10.1037//0033-295X.85.3.207},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Medin, Schaffer{\_}1978{\_}Context theory of classification learning.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {2 attributes,2 options,4 stimuli,Exemplar Model,N,T,categorization,exp,geometry,pic},
mendeley-tags = {2 attributes,2 options,4 stimuli,Exemplar Model,N,T,categorization,exp,geometry,pic},
number = {3},
pages = {207--238},
title = {{Context theory of classification learning.}},
url = {http://content.apa.org/journals/rev/85/3/207},
volume = {85},
year = {1978}
}
@article{Scheibehenne2014,
abstract = {To be useful, cognitive models with fitted parameters should show generalizability across time and allow accurate predictions of future observations. It has been proposed that hierarchical procedures yield better estimates of model parameters than do nonhierarchical, independent approaches, because the formers' estimates for individuals within a group can mutually inform each other. Here, we examine Bayesian hierarchical approaches to evaluating model generalizability in the context of two prominent models of risky choice-cumulative prospect theory (Tversky {\&} Kahneman, 1992) and the transfer-of-attention-exchange model (Birnbaum {\&} Chavez, 1997). Using empirical data of risky choices collected for each individual at two time points, we compared the use of hierarchical versus independent, nonhierarchical Bayesian estimation techniques to assess two aspects of model generalizability: parameter stability (across time) and predictive accuracy. The relative performance of hierarchical versus independent estimation varied across the different measures of generalizability. The hierarchical approach improved parameter stability (in terms of a lower absolute discrepancy of parameter values across time) and predictive accuracy (in terms of deviance; i.e., likelihood). With respect to test-retest correlations and posterior predictive accuracy, however, the hierarchical approach did not outperform the independent approach. Further analyses suggested that this was due to strong correlations between some parameters within both models. Such intercorrelations make it difficult to identify and interpret single parameters and can induce high degrees of shrinkage in hierarchical models. Similar findings may also occur in the context of other cognitive models of choice.},
author = {Scheibehenne, Benjamin and Pachur, Thorsten},
doi = {10.3758/s13423-014-0684-4},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Scheibehenne, Pachur{\_}2014{\_}Using Bayesian hierarchical parameter estimation to assess the generalizability of cognitive models of choice.pdf:pdf},
isbn = {1069-9384},
issn = {1531-5320},
journal = {Psychonomic bulletin {\&} review},
keywords = {bayesian inference,bayesian modeling,decision making,math modeling,parameter estimation},
pages = {391--407},
pmid = {25134469},
title = {{Using Bayesian hierarchical parameter estimation to assess the generalizability of cognitive models of choice.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25134469},
year = {2014}
}
@article{Tversky1992,
abstract = {We develop a new version of prospect theory that employs cumulative rather than separable decision weights and extends the theory in several respects. This version, called cumulative prospect theory, applies to uncertain as well as to risky prospects with any number of outcomes, and it allows different weighting functions for gains and for losses. Two principles, diminishing sensitivity and loss aversion, are invoked to explain the characteris- tic curvature of the value function and the weighting functions. A review of the experimental evidence and the results of a new experiment confirm a distinctive fourfold pattern of risk attitudes: risk aversion for gains and risk seeking for losses of high probability; risk seeking for gains and risk aversion for losses of low probability.},
author = {Tversky, Amos and Kahneman, Daniel},
doi = {10.1007/BF00122574},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Tversky, Kahneman{\_}1992{\_}Advances in prospect theory Cumulative representation of uncertainty.pdf:pdf},
issn = {0895-5646},
journal = {Journal of Risk and Uncertainty},
keywords = {CPT,N,cumulative prospect theory,economics,prospect theory},
mendeley-tags = {CPT,N,cumulative prospect theory,economics,prospect theory},
month = {oct},
number = {4},
pages = {297--323},
title = {{Advances in prospect theory: Cumulative representation of uncertainty}},
url = {http://link.springer.com/10.1007/BF00122574},
volume = {5},
year = {1992}
}
@article{Myung2000,
abstract = {A central problem in science is deciding among competing explanations of data containing random errors. We argue that assessing the "complexity" of explanations is essential to a theoretically well-founded model selection procedure. We formulate model complexity in terms of the geometry of the space of probability distributions. Geometric complexity provides a clear intuitive understanding of several extant notions of model complexity. This approach allows us to reconceptualize the model selection problem as one of counting explanations that lie close to the "truth." We demonstrate the usefulness of the approach by applying it to the recovery of models in psychophysics.},
author = {Myung, In Jae and Balasubramanian, Vijay and Pitt, Mark A.},
doi = {10.1073/pnas.170283897},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Myung, Balasubramanian, Pitt{\_}2000{\_}Counting probability distributions Differential geometry and model selection.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {FIA,fisher information},
mendeley-tags = {FIA,fisher information},
number = {21},
pages = {11170--11175},
pmid = {11005827},
title = {{Counting probability distributions: Differential geometry and model selection}},
volume = {97},
year = {2000}
}
@incollection{Nosofsky2011,
address = {Cambridge, UK},
author = {Nosofsky, Robert M},
booktitle = {Formal approaches in categorization},
chapter = {2},
editor = {Pothos, Emmanuel M and Wills, Andy J},
isbn = {9780521190480},
pages = {18--39},
publisher = {Cambridge University Press},
title = {{The Generalized Context Model: An Exemplar Model of Classification}},
year = {2011}
}
@article{Kass1995,
abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points:},
author = {Kass, Robert E and Raftery, Adrian E},
doi = {10.1080/01621459.1995.10476572},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Kass, Raftery{\_}1995{\_}Bayes Factors.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {BIC,Bayesian Information Criterion,bayesian hypothesis tests,bic,importance sampling,laplace method,markov chain monte carlo,model selection},
mendeley-tags = {BIC,Bayesian Information Criterion},
month = {jun},
number = {430},
pages = {773--795},
title = {{Bayes Factors}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476572},
volume = {90},
year = {1995}
}
@article{Navarro2004,
abstract = {An applied problem is discussed in which two nested psychological mod-els of retention are compared using minimum description length (MDL).The standard Fisher information approximation to the normalized maximum likelihood is calculated for these two models, with the result that the full model is assigned a smaller complexity, even for moderately large samples. A geometric interpretation for this behavior is considered, along with its practical implications.},
author = {Navarro, Daniel J},
doi = {10.1162/0899766041336378},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Navarro{\_}2004{\_}A note on the applied use of MDL approximations.pdf:pdf},
isbn = {10.1162/0899766041336378},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {MDL,minimum description length},
mendeley-tags = {MDL,minimum description length},
number = {9},
pages = {1763--1768},
pmid = {15290794},
title = {{A note on the applied use of MDL approximations.}},
volume = {16},
year = {2004}
}
@article{Stott2006,
abstract = {Many different functional forms have been suggested for both the value function and probability weighting function of Cumulative Prospect Theory (Tversky and Kahneman, 1992). There are also many stochastic choice functions available. Since these three com- ponents only make predictions when considered in combination, this paper examines the complete pattern of 256 model variants that can be constructed from twenty functions. All these variants are fit to experimental data and their explanatory power assessed. Significant interaction effects are observed. The best model has a power value function, a risky weighting function due to Prelec (1998), and a Logit function.},
author = {Stott, Henry P.},
doi = {10.1007/s11166-006-8289-6},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Stott{\_}2006{\_}Cumulative prospect theory's functional menagerie.pdf:pdf},
issn = {0895-5646},
journal = {Journal of Risk and Uncertainty},
keywords = {2 attributes,2 options,2 stimuli,C,CPT,F,allindF,asifM,choice,cogM,des,money,num,perc,prospect theory,rsk},
mendeley-tags = {2 attributes,2 options,2 stimuli,C,CPT,F,allindF,asifM,choice,cogM,des,money,num,perc,prospect theory,rsk},
month = {mar},
number = {2},
pages = {101--130},
title = {{Cumulative prospect theory's functional menagerie}},
url = {http://link.springer.com/10.1007/s11166-006-8289-6},
volume = {32},
year = {2006}
}
@article{Wilson2017,
author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K},
doi = {10.1371/journal.pcbi.1005510},
isbn = {1111111111},
journal = {PLOS Computational Biology},
number = {6},
pages = {1--20},
title = {{Good enough practices in scientific computing}},
volume = {13},
year = {2017}
}
@unpublished{Guest2020,
author = {Guest, Olivia and Martin, Andrea E},
keywords = {challenges for scientific inference,computational model,in psychological,open science,scientific inference,theoretical psychology},
title = {{How Computational Modeling Can Force Theory Building in Psychological Science}},
year = {2020}
}
@article{Nosofsky1986,
abstract = {A unified quantitative approach to modeling Ss' identification and categorization of multidimensional perceptual stimuli is proposed and tested. Two Ss identified and categorized the same set of perceptually confusable stimuli varying on separable dimensions. The identification data were modeled using R. N. Shepard's (see record 1959-05134-001) multidimensional scaling-choice framework, which was then extended to model the Ss' categorization performance. The categorization model, which generalizes the context theory of classification developed by D. L. Medin and M. M. Schaffer (see record 1979-12633-001), assumes that Ss store category exemplars in memory. Classification decisions are based on the similarity of stimuli to the stored exemplars. It is assumed that the same multidimensional perceptual representation underlies performance in both the identification and categorization paradigms. However, because of the influence of selective attention, similarity relationships change systematically across the 2 paradigms. Findings provide some support for the hypothesis that Ss distribute attention among component dimensions so as to optimize categorization performance and that Ss may have augmented their category representations with inferred exemplars. Results demonstrate that excellent predictions of categorization performance can be made given knowledge of performance in an identification paradigm.},
author = {Nosofsky, Robert M},
doi = {10.1037/0096-3445.115.1.39},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Nosofsky{\_}1986{\_}Attention, similarity, and the identification-categorization relationship.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {GCM,Generalized Context Model,N,T,alltrialF,categorization,comM,exemplar model,exp,generalized context model,geometry,indF,pic},
mendeley-tags = {GCM,Generalized Context Model,N,T,alltrialF,categorization,comM,exemplar model,exp,generalized context model,geometry,indF,pic},
number = {1},
pages = {39--57},
title = {{Attention, similarity, and the identification-categorization relationship}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.115.1.39},
volume = {115},
year = {1986}
}
@incollection{Griffiths2008a,
address = {Cambridge, UK},
author = {Griffiths, Thomas L and Kemp, Charles and Tenenbaum, Joshua B},
booktitle = {The Cambridge Handbook of Computational Psychology},
chapter = {3},
editor = {Sun, Ron},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Griffiths, Kemp, Tenenbaum{\_}2008{\_}Bayesian models of cognition.pdf:pdf},
keywords = {BAY,methods},
mendeley-tags = {BAY,methods},
pages = {59--100},
publisher = {Cambridge University Press},
title = {{Bayesian models of cognition}},
year = {2008}
}
@article{Houston1988,
abstract = {We present a general framework for analyzing the contribution to reproductive success of a behavioural action. An action may make a direct contribution to reproductive success, but even in the absence of a direct contribution it may make an indirect contribution by changing the animal's state. We consider actions over a period of time, and define a reward function that characterizes the relationship between the animal's state at the end of the period and its future reproductive success. Working back from the end of the period using dynamic programming, the optimal action as a function of state and time can be found. The procedure also yields a measure of the cost, in terms of future reproductive success, of a suboptimal action. These costs provide us with a common currency for comparing activities such as eating and drinking, or eating and hiding from predators. The costs also give an indication of the robustness of the conclusions that can be drawn from a model. We review how our framework can be used to analyze optimal foraging decisions in a stochastic environment. We also discuss the modelling of optimal daily routines and provide an illustration based on singing to attract a mate. We use the model to investigate the features that can produce a dawn song burst in birds. State is defined very broadly so that it includes the information an animal has about its environment. Thus, exploration and learning can be included within the framework. Keywords:},
author = {Houston, Alasdair I and McNamara, John M},
doi = {10.1017/S0140525X00053061},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop//Houston, McNamara{\_}1988{\_}A framework for the functional analysis of behaviour.pdf:pdf},
journal = {Behavioural and Brain Science},
keywords = {action seelction,evolution,foraging,optimization,risk-sensitive foraging},
mendeley-tags = {action seelction,evolution,optimization,risk-sensitive foraging},
pages = {117--163},
title = {{A framework for the functional analysis of behaviour}},
volume = {11},
year = {1988}
}
@article{Wakker2008,
abstract = {The power family, also known as the family of constant relative risk aversion (CRRA), is the most widely used parametric family for fitting utility functions to data. Its characteristics have, however, been little understood, and have led to numerous misunderstandings. This paper explains these characteristics in a manner accessible to a wide audience.},
author = {Wakker, Peter P.},
doi = {10.1002/hec.1331},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Wakker{\_}2008{\_}Explaining the characteristics of the power (CRRA) utility family.pdf:pdf},
issn = {10579230},
journal = {Health Economics},
keywords = {constant,constant proportional trade-offs,crra,economics,elasticity of substitution,power utility,quality-of-life measurement,utility,utility measurement},
mendeley-tags = {economics,power utility,utility},
month = {dec},
number = {12},
pages = {1329--1344},
title = {{Explaining the characteristics of the power (CRRA) utility family}},
url = {http://doi.wiley.com/10.1002/hec.1331},
volume = {17},
year = {2008}
}
@article{Jarecki2020,
author = {Jarecki, Jana B and Tan, Jolene H and Jenny, Mirjam A},
doi = {10.3758/s13423-020-01747-2},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Jarecki, Tan, Jenny{\_}2020{\_}A Framework for Building Cognitive Process Models.pdf:pdf},
institution = {Psychonomic Bulletin {\&} Review},
journal = {Psychonomic Bulletin {\&} Review},
keywords = {intercoder reliability},
mendeley-tags = {intercoder reliability},
title = {{A Framework for Building Cognitive Process Models}},
year = {2020}
}

@article{Rooij2020,
abstract = {We present a tutorial for formalizing verbal theories of psychological phenomena—social or otherwise. The approach builds on concepts and tools from the mathematics of computation. We use intuitive examples and illustrate the intrinsic dialectical nature of the formalization process by presenting dialogues between two fictive characters, called Verbal and Formal. These characters' conversations and thought experiments serve to highlight important lessons in theoretical modeling.},
author = {Van Rooij, Iris and Blokpoel, Mark},
doi = {10.31234/osf.io/r2zqy},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Rooij, Blokpoel{\_}2020{\_}Formalizing verbal theories A tutorial by dialogue.pdf:pdf},
keywords = {computational explanation,computational model,formal model,formalization,methods,theoretical modeling,tutorial,verbal theory},
mendeley-tags = {methods,formal model,tutorial,computational model},
title = {{Formalizing verbal theories: A tutorial by dialogue}},
url = {https://psyarxiv.com/r2zqy},
year = {2020}
}
@article{Rooij2020theory,
abstract = {Drawing on the philosophy of psychological explanation (Cummins, 1983; 2000), we suggest that psychological science, by focusing on effects, may lose sight of its primary explananda: psychological capacities. We revisit Marr's (1982) levels-of-analysis framework, which has been remarkably productive and useful for cognitive psychological explanation. We discuss ways in which Marr's framework may be extended to other areas of psychology, such as social, developmental, and evolutionary psychology, bringing new benefits to these fields. Next, we show how theoretical analyses can endow a theory with minimal plausibility even prior to contact with empirical data: we call this the theoretical cycle. Finally, we explain how our proposal may contribute to addressing critical issues in psychological science, including how to leverage effects to understand capacities better.},
archivePrefix = {arXiv},
arxivId = {10.31234/osf.io/7qbpr},
author = {{Van Rooij}, Iris and Baggio, Giosu{\`{e}}},
eprint = {osf.io/7qbpr},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Van Rooij, Baggio{\_}2020{\_}Theory before the test How to build high-verisimilitude explanatory theories in psychological science.pdf:pdf},
keywords = {computational analysis,computational-level theory,formal model,formal modeling,levels of explanation,methods,psychological explanation,replicability,theory development},
mendeley-tags = {methods,formal model,replicability},
primaryClass = {10.31234},
title = {{Theory before the test: How to build high-verisimilitude explanatory theories in psychological science}},
url = {https://psyarxiv.com/7qbpr/},
year = {2020}
}

@article{Achinstein1965,
abstract = {THE term model enjoys a broad range of uses m the sciences. It may refer to anything from a physical construction m a display case to an abstract set of ideas. Here I shall examine one important use of the term in physics, illustrated by examples such as the Bohr model of the atom, the billiard ball model of gases, the corpuscular model of light, the shell model of the atormc nucleus, and the free-electron model of metals. These I shall refer to as theoretical models, or models, for short. It is not my claim that everything called a model in physics can be shown to be a model m the present sense. Indeed, I shall argue, these models are quite distinct from other conceptions sometimes called models. It is my aim to show that the examples I have cited, as well as many others that might have beencited,have certain commoncharacter- istics min virtue of which they are referred to a},
author = {Achinstein, Peter},
doi = {10.1093/bjps/XVI.62.102},
file = {:C$\backslash$:/Users/jjarecki/Documents/Mendeley Desktop/Achinstein{\_}1965{\_}Theoretical Models.pdf:pdf},
issn = {0007-0882},
journal = {The British Journal for the Philosophy of Science},
keywords = {model,philosophy},
mendeley-tags = {model,philosophy},
number = {62},
pages = {102--120},
title = {{Theoretical Models}},
url = {https://academic.oup.com/bjps/article-lookup/doi/10.1093/bjps/XVI.62.102},
volume = {XVI},
year = {1965}
}
@article{Lee2019,
author = {Lee, Michael D and Chriss, Amy H and Vandekerckhove, Joachim},
doi = {10.1007/s42113-019-00029-y},
journal = {Computational Brain {\&} Behavior},
keywords = {cognitive modeling,meta-science,robustness},
mendeley-tags = {meta-science,robustness,cognitive modeling},
pages = {141--153},
title = {{Robust Modeling in Cognitive Science}},
volume = {2},
year = {2019}
}

@book{Sutton2018,
abstract = {This paper discusses problems typical of eliciting housing preference. It will be argued that stated preference and choice models are potentially powerful in eliciting consumer housing preferences. This approach is illustrated in an example of new housing construction in Meerhoven. The design of the stated choice experiment is outlined and the estimated part-worth utilities of the attributes are presented. Furthermore, choices for houses in low- and high-density environments are predicted and its is examined how much more households are willing to pay for low-density housing.},
author = {Sutton, Richard S and Barto, Andrew G},
edition = {2},
keywords = {machine learning,reinforcement learning},
mendeley-tags = {machine learning,reinforcement learning},
publisher = {MIT Press},
title = {{Reinforcment learning: an introduction}},
year = {2018}
}
