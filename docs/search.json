[{"path":"/articles/used_in.html","id":"scientific-work-in-which-cognitivemodels-is-in-use","dir":"Articles","previous_headings":"","what":"Scientific work in which cognitivemodels is in use","title":"Used in","text":"Predicting human preferences Modeling risky decision making goals Modelingn risky decision making gain-loss framing effects Testing Models human categorization Investigation Learning Risks","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jana Jarecki. Author, maintainer. Florian Seitz. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jarecki J, Seitz F (2022). cognitivemodels: Cognitive Models - Estimation, Prediction, Development Models Cognitive Scientists. R package version 0.0.12.","code":"@Manual{,   title = {cognitivemodels: Cognitive Models - Estimation, Prediction, and Development of Models for Cognitive Scientists},   author = {Jana Jarecki and Florian Seitz},   year = {2022},   note = {R package version 0.0.12}, }"},{"path":"/index.html","id":"section","dir":"","previous_headings":"","what":"An R package for cognitive modeling","title":"An R package for cognitive modeling","text":"cognitivemodels offers user-friendly collection machine-learning algorithms train test models human learning, behavior, cognition. syntax uses formula interface resembling aov(y ~ x)- lm(y ~ x)-syntax. models can fit data maximum likelihood, minimum MSE, fit measures Chose optimization routines like rsolnp Nelder-Mead, among others Also, package provides model development back end, .e. class develop new cognitive models easily","code":""},{"path":"/index.html","id":"news","dir":"","previous_headings":"","what":"News","title":"An R package for cognitive modeling","text":"can see latest package version’s new features NEWS.","code":""},{"path":"/index.html","id":"models-in-this-package","dir":"","previous_headings":"","what":"Models in this Package","title":"An R package for cognitive modeling","text":"following models implemented:","code":""},{"path":"/index.html","id":"installing-the-package","dir":"","previous_headings":"","what":"Installing the Package","title":"An R package for cognitive modeling","text":"use package, ensure working installation R Rcpp package, install.packages(\"Rcpp\"), help problems see Installation Troubleshooting see prompt, please type Yes console. use package, run: (Optional) installs newest version (development version) package:","code":"library(devtools)     install.packages(\"matlib\")     install.packages(\"Rcpp\")     # Restart the R session after installing matlib!      devtools::install_github(\"janajarecki/cognitivemodels\") Do you want to install from sources the packages which need compilation? (Yes/no/cancel) library(cognitivemodels) devtools::install_github(\"janajarecki/cognitivemodels\" ref = \"development\")"},{"path":"/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"An R package for cognitive modeling","text":"can read quick introduction package ICCM article; can view example modeling code . Example. Let’s fit data supervised categorization task. Background. task people learn categorize many lines differed two features (size tilting angle) two categories, providing feedback true category (Nosofsky, 1989). collected data can loaded ba running data(nosofsky1989long). Let’s model data one condition data set called “size”. Code. syntax loads data sets model, explained code.","code":"# Use the 'size' condition in the data   data(nosofsky1989long)   DT <- nosofsky1989long   DT <- DT[DT$condition==\"size\", ]   D  <- DT[!is.na(DT$true_cat), ]      # Fit the model to the data D   model <- gcm(     formula = response ~ angle + size,     class = ~ true_cat,     data = D,     choicerule = \"none\")"},{"path":"/index.html","id":"installation-troubleshooting","dir":"","previous_headings":"Getting Started","what":"Installation Troubleshooting","title":"An R package for cognitive modeling","text":"error messages installation troubleshoot : Error: Failed install 'cognitivemodels' GitHub:   find tools necessary compile package Callpkgbuild::check_build_tools(debug = TRUE)diagnose problem. Solution: R, must run options(buildtools.check = function(action) TRUE ) solve problem, details see Error: xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun : Solution need install xcode Mac opening terminal running xcode-select --install install command lines tools package details stackoverflow","code":""},{"path":"/index.html","id":"authors","dir":"","previous_headings":"","what":"Authors","title":"An R package for cognitive modeling","text":"Jana B. Jarecki, Florian . Seitz","code":""},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"An R package for cognitive modeling","text":"project licensed CC-Attribution 4.0 International","code":""},{"path":"/reference/albrecht2019exp1.html","id":null,"dir":"Reference","previous_headings":"","what":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","title":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","text":"Data judgments.","code":""},{"path":"/reference/albrecht2019exp1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","text":"object class \"data.frame\".","code":""},{"path":"/reference/albrecht2019exp1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","text":"subj. Subject ID trial. Trial numner name. stimulus name f1. Feature value one f2. Feature value two f2. Feature value three time. Reaction time test. condition. Experimental condition","code":""},{"path":"/reference/albrecht2019exp1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","text":"Albrecht, R., Hoffmann, J. ., Pleskac, T. J., Rieskamp, J., & von Helversen, B. (2019). Competitive Retrieval Strategy Causes Multimodal Response Distributions Multiple-Cue Judgments. Journal Experimental Psychology: Memory, Learning & Cognition.","code":""},{"path":"/reference/albrecht2019exp1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test data for fitting the Exemplar-based judgment model — albrecht2019exp1","text":"","code":"data(albrecht2019exp1)"},{"path":"/reference/anova.cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of Deviance for Cogscimodel Fits — anova.cm","title":"Analysis of Deviance for Cogscimodel Fits — anova.cm","text":"anova returns analysis deviance table one fitted cognitive models","code":""},{"path":"/reference/anova.cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of Deviance for Cogscimodel Fits — anova.cm","text":"","code":"# S3 method for cm anova(object, ...)"},{"path":"/reference/anova.cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of Deviance for Cogscimodel Fits — anova.cm","text":"object, ... Objects class cm, typically result call one fo models. (list objects \"cm_list\" method.)","code":""},{"path":"/reference/anova.cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of Deviance for Cogscimodel Fits — anova.cm","text":"anova-style table","code":""},{"path":"/reference/anova.cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of Deviance for Cogscimodel Fits — anova.cm","text":"","code":"# None yet."},{"path":"/reference/baseline.html","id":null,"dir":"Reference","previous_headings":"","what":"Baseline models — baseline_const_c","title":"Baseline models — baseline_const_c","text":"Fits baseline models. Baseline models stimulus-agostic models used sanity checks cognitive model comparisons. cognitive models beat baseline model -- , cognitive models describe patterns responses well. baseline_const_c() predicts constant value continuous responses. baseline_const_d() predicts constant value discrete responses. baseline_mean_c() fits mean observed responses continuous responses. baseline_mean_d() fits mean observed responses discrete responses.","code":""},{"path":"/reference/baseline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Baseline models — baseline_const_c","text":"","code":"baseline_const_c(formula, const, data, options, discount, ...)  baseline_const_d(formula, const, data, ...)  baseline_mean_c(formula, data, ...)  baseline_mean_d(formula, data, ...)"},{"path":"/reference/baseline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Baseline models — baseline_const_c","text":"formula formula, variable data modeled. example, y ~ . models response variable y (note ~ . variable name). const number, value predict. data data frame, data modeled. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. discount number, many initial trials use parameter fitting. ... arguments, ignored.","code":""},{"path":"/reference/baseline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Baseline models — baseline_const_c","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/baseline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Baseline models — baseline_const_c","text":"baseline_const_c/d predicts value given const trials. example const = 0.50 predict Pr=0.50 trial, commmon baseline model tasks two-outcome discrete choices.","code":""},{"path":"/reference/baseline.html","id":"parameter","dir":"Reference","previous_headings":"","what":"Parameter","title":"Baseline models — baseline_const_c","text":"baseline_const_c/d free parameter baseline_mean_c/d 1 free parameter, mu, mean baseline_mean_c, estimated via log likelihood, additional free parameter, sigma, standard deviation normal log likelihood.","code":""},{"path":[]},{"path":"/reference/baseline.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Baseline models — baseline_const_c","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/baseline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Baseline models — baseline_const_c","text":"","code":"# Data D: let y hold the observed responses # Make a model that predicts Pr = 0.50 D <- data.frame(y = c(1,1,0), x = c(1,2,3)) M <- baseline_const_d(y ~ ., const = 0.50, data = D) predict(M)                         # predicts 0.5, 0.5, 0.5 #> [1] 0.5 0.5 0.5 npar(M)                            # 0 parameter #> [1] 0 logLik(M)                          # log likelihood (binomial) #> 'log Lik.' -2.079442 (df=0)  M <- baseline_mean_d(y ~ ., D)     # Pr = mean(observed variable) #> Fitting free parameters [mu] by maximizing loglikelihood (binomial pdf) with auto. #> Error: Can't compute the goodness of fit loglikelihood, because: #>   Error in log(pred) : non-numeric argument to mathematical function predict(M)                         # predicts 0.66, 0.66, 0.66 #> [1] 0.5 0.5 0.5 coef(M)                            # mean counts as free parameter #> NULL npar(M)                            # 1 free parameter, the mean #> [1] 0"},{"path":"/reference/bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Inference Cognitive Model — bayes","title":"Bayesian Inference Cognitive Model — bayes","text":"bayes() fits Bayesian cognitive model, updating beliefs probability discrete event outcomes based frequencies outcomes. bayes_beta_c() fits model 2 outcomes (beta-binomial) continuous responses bayes_beta_d() fits model 2 outcomes (beta-binomial) discrete responses bayes_dirichlet_c() fits model n > 2 outcomes (dirichlet-categorical/multinomial) continuous responses bayes_dirichlet_d() fits model n > 2 outcomes (dirichlet-categorical/multinomial) discrete responses","code":""},{"path":"/reference/bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Inference Cognitive Model — bayes","text":"","code":"bayes_beta_c(   formula,   data,   fix = NULL,   format = c(\"raw\", \"count\", \"cumulative\"),   prior_sum = NULL,   ... )  bayes_beta_d(formula, data, fix = NULL, format = NULL, prior_sum = NULL, ...)  bayes_dirichlet_d(   formula,   data,   fix = NULL,   format = NULL,   prior_sum = NULL,   ... )  bayes_dirichlet_c(   formula,   data,   fix = NULL,   format = NULL,   prior_sum = NULL,   ... )  bayes(   formula,   data = data.frame(),   fix = list(),   format = c(\"raw\", \"count\", \"cumulative\"),   type = NULL,   discount = 0L,   options = list(),   prior_sum = NULL,   ... )"},{"path":"/reference/bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Inference Cognitive Model — bayes","text":"formula formula, variables data modeled. example, y ~ x1 + x2 models response y function one stimulus features x1, x2. data data frame, data modeled. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names depend formula can delta, x1, x2 (see details - model parameters). list(x1 = 3.09) sets parameter x1 equal 3.09. list(x1 = \"x2\") sets parameter x1 equal parameter x2 (estimates x2). list(x2 = \"x1\", x1 = 3.09) sets parameter x2 equal parameter x1 sets x1 equal 3.09 (estimates none two). list(x1 = NA) omits parameter x1, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. format (optional) string, format data modeled, can abbreviated, default \"raw\"; allowed values: \"raw\" means data trial--trial binary occurrence indicators: 1, 0, 1, ... means event happened trial value 1. \"cumulative\" means data trial--trial cumulative counts events: 0, 1, 1, 2, ... counts often event happened trial. \"count\" means data total events counts, ignoring trial--trial order events: 2, 10, ... means event happened 2 times, (starting zero!) happened 10 times. prior_sum (optional) number; prior hyperparameter constrained sum number; defaults number prior parameters; prior_sum = NA sum constraint placed. ... arguments, ignored. type (optional) string, type inference, \"beta-binomial\" \"dirichlet-multinomial\". Can abbreviated. inferred, missing. discount number, many initial trials use parameter fitting. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options.","code":""},{"path":"/reference/bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Inference Cognitive Model — bayes","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Inference Cognitive Model — bayes","text":"model models -- response -- belief occurrence first event formula follows: y ~ x1 models beliefe event x1 occurring versus occurring. y ~ x1 + x2 models beliefs x1 versus x2 occurring. y ~ x1 + x2 + x3 models beliefs x1, x2, x3 occurring.","code":""},{"path":"/reference/bayes.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Bayesian Inference Cognitive Model — bayes","text":"model n + 1 (n = number events) free parameters, : delta learning rate, weights observation learning, value < 1 causes conservatism, > 1 causes liberal learning, 1 optimal Bayesian. x1, x2 (dynamic names) prior parameter, names correspond right side formula. Also known hyperparameter prior belief distribution trial 1. constrainted sum n n - 1 parameter estimated. bayes_beta_d() bayes_dirichlet_d(): choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":"/reference/bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Inference Cognitive Model — bayes","text":"Griffiths, T. L., & Yuille, . (2008). Technical Introduction: primer probabilistic inference. N. Chater & M. Oaksford (Eds.), Probabilistic Mind: Prospects Bayesian Cognitive Science (pp. 1 - 2). Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199216093.003.0002 Tauber, S., Navarro, D. J., Perfors, ., & Steyvers, M. (2017). Bayesian models cognition revisited: Setting optimality aside letting data drive psychological theory. Psychological Review, 124(4), 410 - 441. http://dx.doi.org/10.1037/rev0000052","code":""},{"path":[]},{"path":"/reference/bayes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Inference Cognitive Model — bayes","text":"Markus Steiner Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/bayes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Inference Cognitive Model — bayes","text":"","code":"D <- data.frame(   a = c(0,0,1,1,1),              # event A, e.g. coin toss \"heads\"   b = c(1,1,0,0,0),              # event B, complement of A   y = c(0.5,0.3,0.2,0.3,0.5))    # participants' beliefs about A  M <- bayes_beta_c(      formula = y ~ a + b,      data = D)   # fit all parameters #> Fitting free parameters [delta, a, sigma] by maximizing loglikelihood (truncnorm pdf) with solnp. predict(M)                        # predict posterior means #> [1] 0.4879909 0.2804911 0.1968065 0.3813738 0.4969667 summary(M)                        # summarize model #>  #> Model: #>   with no choice rule #> Call: #> y ~ a + b #>  #> (Constrained) Parameters: #>       Estimate #> delta 1.48     #> a     0.976    #> b     1.024    #> sigma 0.03786  #>  #> Fit Measures: #> MSE: 0.0014, LL: 9.3, AIC: -9.5, BIC: -14 #>  parspace(M)                       # view parameter space #>  #> Parameter space of the cognitive model 'Bayesian model': #>               lb         ub      start         na #> delta  0.0000000 10.0000000  1.0000000  1.0000000 #> a      0.0000100  2.0000000  1.0000000  1.0000000 #> b      0.0000100  2.0000000  1.0000000  1.0000000 #> sigma  0.0000001  0.3000000  0.1500000         NA #> --- #> Note. lb = lower bound, ub = upper bound, start = start value. anova(M)                          # anova-like table #> Sum Sq. Table #>  N Par    Sum Sq   Mean Sq #>      3 0.0071659 0.0014332 logLik(M)                         # loglikelihood #> 'log Lik.' 9.274954 (df=3) MSE(M)                            # mean-squared error    #> [1] 0.001433182   # Predictions ---------------------------------------------- predict(M, type = \"mean\")                  # posterior mean #> [1] 0.4879909 0.2804911 0.1968065 0.3813738 0.4969667 predict(M, type = \"max\")                   # maximum posterior #> [1]         -Inf -0.016233531 -0.008116766  0.327922156  0.495941617 predict(M, type = \"sd\")                    # posterior SD #> [1] 0.2885919 0.2122563 0.1628695 0.1780914 0.1674263 predict(M, type = \"posteriorpar\")          # posterior hyper-par. #>           pr_a     pr_s #> [1,] 0.9759817 1.024018 #> [2,] 0.9759817 2.503564 #> [3,] 0.9759817 3.983111 #> [4,] 2.4555279 3.983111 #> [5,] 3.9350741 3.983111 predict(M, type = \"draws\", ndraws = 3)     #  --\"--  3 draws #> Warning: These arguments to 'predict.cogscimodel' are invalid and dropped: list(ndraws = 3) #>          pr_a1      pr_a2     pr_a3     pr_s1     pr_s2     pr_s3 #> [1,] 0.7670014 0.08891222 0.8822279 0.2329986 0.9110878 0.1177721 #> [2,] 0.1183597 0.08963572 0.4461487 0.8816403 0.9103643 0.5538513 #> [3,] 0.3198218 0.22440427 0.1483428 0.6801782 0.7755957 0.8516572 #> [4,] 0.1077867 0.23328954 0.5782826 0.8922133 0.7667105 0.4217174 #> [5,] 0.6082902 0.60249920 0.3373560 0.3917098 0.3975008 0.6626440   # Fix parameter --------------------------------------------- bayes_beta_c(~a+b, D, list(delta=1, priorpar=c(1, 1)))  # delta=1, uniform prior #> Fitting free parameters [sigma] by maximizing loglikelihood (truncnorm pdf) with solnp. #> Error: Can't compute goodness of fit, because the model has no observed resonses.. #>   * Did you forget a left side in 'formula'? (such as 'y' in y ~ x1 + x2) bayes_beta_c(~a+b, D, list(delta=1, a=1, b=1))          # -- (same) -- #> Fitting free parameters [sigma] by maximizing loglikelihood (truncnorm pdf) with solnp. #> Error: Can't compute goodness of fit, because the model has no observed resonses.. #>   * Did you forget a left side in 'formula'? (such as 'y' in y ~ x1 + x2) bayes_beta_c(~a+b, D, fix = \"start\")                    # fix to start values #> Bayesian model | choice rule: none #> Call: #> bayes_beta_c(formula = ~a + b, data = D, fix = \"start\") #>  #> Constrained and fixed parameters: #> delta      a      b  sigma   #>   1.0    1.0    1.0    0.5   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.)   # Parameter fitting ---------------------------------------- # Use a response variable, y, to which we fit parameter bayes(y ~ a + b, D, fix = \"start\")              # \"start\" fixes all par., fit none  #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = \"start\") #>  #> Constrained and fixed parameters: #> delta      a      b  sigma   #>  1.00   1.00   1.00   0.15   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, fix = list(delta=1))         # fix delta, fit priors  #> Fitting free parameters [a, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(delta = 1)) #>  #> Free parameters: estimates  #>     a  sigma   #> 0.911  0.044   #>  #> Constrained and fixed parameters: #> delta      b   #>   1.0    1.1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, fix = list(a=1, b=1))        # fix priors, fit delta  #> Fitting free parameters [delta, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(a = 1, b = 1)) #>  #> Free parameters: estimates  #> delta  sigma   #> 1.560  0.038   #>  #> Constrained and fixed parameters: #>    a     b   #>    1     1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, fix = list(delta=1, a=1))    # fix delta & prior on \"a\" #> Fitting free parameters [sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(delta = 1, a = 1)) #>  #> Free parameters: estimates  #> sigma   #> 0.052   #>  #> Constrained and fixed parameters: #> delta      a      b   #>     1      1      1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, list(delta=1, b=1))          # fix delta & prior on \"b\" #> Fitting free parameters [sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(delta = 1, b = 1)) #>  #> Free parameters: estimates  #> sigma   #> 0.052   #>  #> Constrained and fixed parameters: #> delta      a      b   #>     1      1      1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.)   ### Parameter meanings # --------------------------------------- # delta parameter: the learning rate or evidence weight bayes(y ~ a + b, D, c(delta = 0))             # 0   -> no learning #> Fitting free parameters [a, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = c(delta = 0)) #>  #> Free parameters: estimates  #>     a  sigma   #>  0.72   0.12   #>  #> Constrained and fixed parameters: #> delta      b   #>   0.0    1.3   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, c(delta = 0.1))           # 0.1 -> slow learning #> Fitting free parameters [a, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = c(delta = 0.1)) #>  #> Free parameters: estimates  #>     a  sigma   #>  0.74   0.10   #>  #> Constrained and fixed parameters: #> delta      b   #>   0.1    1.3   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, c(delta = 9))             # 9   -> fast learning #> Fitting free parameters [a, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = c(delta = 9)) #>  #> Free parameters: estimates  #>     a  sigma   #>  1.10   0.11   #>  #> Constrained and fixed parameters: #> delta      b   #>   9.0    0.9   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, c(a=1.5, b=0.5))                # prior: a more likely #> Fitting free parameters [delta, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = c(a = 1.5, b = 0.5)) #>  #> Free parameters: estimates  #> delta  sigma   #>  3.33   0.12   #>  #> Constrained and fixed parameters: #>    a     b   #>  1.5   0.5   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, list(priorpar=c(1.5, 0.5)))     # -- (same) -- #> Fitting free parameters [delta, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(priorpar = c(1.5,  ... #>  #> Free parameters: estimates  #> delta  sigma   #>  3.33   0.12   #>  #> Constrained and fixed parameters: #>    a     b   #>  1.5   0.5   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, c(a = 0.1, b=1.9))              # prior: b more likely #> Fitting free parameters [delta, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = c(a = 0.1, b = 1.9)) #>  #> Free parameters: estimates  #> delta  sigma   #>  2.68   0.25   #>  #> Constrained and fixed parameters: #>    a     b   #>  0.1   1.9   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) bayes(y ~ a + b, D, list(priorpar = c(0.1, 1.9)))   # -- (same) -- #> Fitting free parameters [delta, sigma] by maximizing loglikelihood (normal pdf) with solnp. #> Bayesian model | choice rule: none #> Call: #> bayes(formula = y ~ a + b, data = D, fix = list(priorpar = c(0.1,  ... #>  #> Free parameters: estimates  #> delta  sigma   #>  2.68   0.25   #>  #> Constrained and fixed parameters: #>    a     b   #>  0.1   1.9   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.)"},{"path":"/reference/choicerules.html","id":null,"dir":"Reference","previous_headings":"","what":"Choicerule Models (action-selection rules) — choicerules","title":"Choicerule Models (action-selection rules) — choicerules","text":"Models discrete action selection: applies choce rule/decision rule/action selection rule select among values. softmax() fits soft-maximum = soft approximation argmax (Sutton & Barto, 2018). epsilon_greedy() fits epsilon-greedy. epsilon() fits probabilistic-epsilon. argmax() maximizes deterministically. luce() selects proportionally (Luce's rule aka Luce's axiom, Luce, 1959).","code":""},{"path":"/reference/choicerules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choicerule Models (action-selection rules) — choicerules","text":"","code":"softmax(formula, data, fix = list(), options = NULL)  epsilon_greedy(formula, data, fix = list(), options = NULL)  epsilon(formula, data, fix = list(), options = NULL)  luce(formula, data, ...)  argmax(formula, data, ...)"},{"path":"/reference/choicerules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choicerule Models (action-selection rules) — choicerules","text":"formula formula, variables data modeled. example, y ~ x1 | x2 models response y function two stimuli values x1 x2 (respectively). Lines | separate stimuli. data data frame, data modeled. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names tau (see details - model parameters). list(tau = 3.85) sets parameter tau equal 3.85. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. ... arguments, ignored. discount number, many initial trials use parameter fitting.","code":""},{"path":"/reference/choicerules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choicerule Models (action-selection rules) — choicerules","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/choicerules.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Choicerule Models (action-selection rules) — choicerules","text":"model predicts treats observations: formula = y ~ x1 y ~ x1 | x2 predicts probability select x1, thus y = 1 must mean select x1. formula = y ~ x1 | x2 | x3 predicts three columns, probabilities select x1, x2, x3, respectively.","code":""},{"path":"/reference/choicerules.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Choicerule Models (action-selection rules) — choicerules","text":"models free parameters, except softmax epsilon greedy 1 free parameter : softmax(): tau: softness choices, high values cause equiprobable choices. epsilon() epsilon_greedy(): eps: error proportion choices, high values cause errors.","code":""},{"path":"/reference/choicerules.html","id":"background","dir":"Reference","previous_headings":"","what":"Background","title":"Choicerule Models (action-selection rules) — choicerules","text":"epsilon() picks action \\(\\) probability \\((1 - \\epsilon)*p()\\) \\(\\epsilon\\) picks randomly actions. \\(\\epsilon = 0\\) gives \\(p()\\),  original probabilistic policy. epsilon_greedy() picks best action probability \\(1 - \\epsilon\\), \\(\\epsilon\\) picks randomly actions, including best. argmax() picks highest-valued action probability 1, case ties picks equiprobable. luce() picks action \\(\\) probability \\(v() / \\sum v\\).","code":""},{"path":"/reference/choicerules.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Choicerule Models (action-selection rules) — choicerules","text":"Sutton, R. S., & Barto, . G. (2018). Reinforcement Learning: Introduction (2nd Ed.). MIT Press, Cambridge, MA. (http://incompleteideas.net/book/-book-2nd.html) Luce, R. D. (1959). possible psychophysical laws. Psychological Review, 66(2), 81-95. doi:10.1037/h0043178","code":""},{"path":[]},{"path":"/reference/choicerules.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Choicerule Models (action-selection rules) — choicerules","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/choicerules.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Choicerule Models (action-selection rules) — choicerules","text":"","code":"# Make some fake data D <- data.frame(a = c(.3,.8,.5),       # value of option A                 b = c(.7,.2,.5),       # value of option B                 y = c(0,1,1))          # respondent's choice (0=A, 1=B)  M <- softmax(y ~ a | b, D, c(tau=1))   # creates soft-max model w tau=1  predict(M)                             # predict action selection #> [1] 0.4013123 0.6456563 0.5000000 M$predict()                            # -- (same) -- #> [1] 0.4013123 0.6456563 0.5000000 summary(M)                             # summarize #>  #> Model: #>   with no choice rule #> Call: #> y ~ a | b #>  #> No Free Parameters #>  #> Fit Measures: #> MSE: 0.18, LL: -1.6, AIC: 3.3, BIC: 3.3 #>  anova(M)                               # anova-like table #> Sum Sq. Table #>  N Par  Sum Sq Mean Sq #>      0 0.53661 0.17887 coef(M)                                # free parameter (NULL) #> NULL M$get_par()                            # fixed parameter (tau = 1) #> tau  #>   1  M$npar()                               # 1 parameter #> [1] 0 M$MSE()                                # mean-squared error #> [1] 0.1788703 logLik(M)                              # log likelihood #> 'log Lik.' -1.64365 (df=0)   ### Parameter specification and fitting --------------------------------- softmax(y ~ a | b, D, fix=\"start\")     # fix 'tau' to its start value #> softmax | choice rule: none #> Call: #> softmax(formula = y ~ a | b, data = D, fix = \"start\") #>  #> Constrained and fixed parameters: #>  tau   #>    2   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) softmax(y ~ a | b, D, fix=c(tau=0.2))  # fix 'tau' to 0.2 #> softmax | choice rule: none #> Call: #> softmax(formula = y ~ a | b, data = D, fix = c(tau = 0.2)) #>  #> Constrained and fixed parameters: #>  tau   #>  0.2   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) softmax(y ~ a | b, D)                  # fit 'tau' to data y in D #> Fitting free parameters [tau] by maximizing loglikelihood (binomial pdf) with auto. #> softmax | choice rule: none #> Call: #> softmax(formula = y ~ a | b, data = D) #>  #> Free parameters: estimates  #>   tau   #> 1e-04   #>  #>  #> --- #> Note:  No fixed parameter.    ### The different choice rules ------------------------------------------ softmax(y ~ a | b, D,  fix=c(tau=0.5)) # fix 'tau' to 0.5 #> softmax | choice rule: none #> Call: #> softmax(formula = y ~ a | b, data = D, fix = c(tau = 0.5)) #>  #> Constrained and fixed parameters: #>  tau   #>  0.5   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) softmax(y ~ a | b, D)                  # fit 'tau' to y #> Fitting free parameters [tau] by maximizing loglikelihood (binomial pdf) with auto. #> softmax | choice rule: none #> Call: #> softmax(formula = y ~ a | b, data = D) #>  #> Free parameters: estimates  #>   tau   #> 1e-04   #>  #>  #> --- #> Note:  No fixed parameter.  epsilon_greedy(y~a | b, D, c(eps=0.1)) # fix 'eps' to 10 % #> epsilongreedy | choice rule: none #> Call: #> epsilon_greedy(formula = y ~ a | b, data = D, fix = c(eps = 0.1)) #>  #> Constrained and fixed parameters: #>  eps   #>  0.1   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) epsilon_greedy(y~a | b, D )            # fit 'eps' to y #> Fitting free parameters [eps] by maximizing loglikelihood (binomial pdf) with auto. #> epsilongreedy | choice rule: none #> Call: #> epsilon_greedy(formula = y ~ a | b, data = D) #>  #> Free parameters: estimates  #>  eps   #>    0   #>  #>  #> --- #> Note:  No fixed parameter.  epsilon(y ~ a | b, D, c(eps=0.1))      # fix 'eps' to 0.1 #> epsilon | choice rule: none #> Call: #> epsilon(formula = y ~ a | b, data = D, fix = c(eps = 0.1)) #>  #> Constrained and fixed parameters: #>  eps   #>  0.1   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.) epsilon(y ~ a | b, D)                  # fit 'eps' to y #> Fitting free parameters [eps] by maximizing loglikelihood (binomial pdf) with auto. #> epsilon | choice rule: none #> Call: #> epsilon(formula = y ~ a | b, data = D) #>  #> Free parameters: estimates  #>  eps   #>    0   #>  #>  #> --- #> Note:  No fixed parameter.  luce(y ~ a | b, D)                     # Luce's choice rule, 0 parameter #> luce | choice rule: none #> Call: #> luce(formula = y ~ a | b, data = D) #>  #>  #> --- #> Note:  No free parameters. No fixed parameter.  argmax(y ~ a | b, D)                   # Argmax choice rule, 0 parameter #> argmax | choice rule: none #> Call: #> argmax(formula = y ~ a | b, data = D) #>  #>  #> --- #> Note:  No free parameters. No fixed parameter."},{"path":"/reference/chr_as_rhs.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a character to formula — chr_as_rhs","title":"Convert a character to formula — chr_as_rhs","text":"Checks x character converts RHS formula","code":""},{"path":"/reference/chr_as_rhs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a character to formula — chr_as_rhs","text":"","code":"chr_as_rhs(x)"},{"path":"/reference/chr_as_rhs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a character to formula — chr_as_rhs","text":"x string RHS formula","code":""},{"path":"/reference/Cm.html","id":null,"dir":"Reference","previous_headings":"","what":"The R6 class underlying all ","title":"The R6 class underlying all ","text":"R6 class underlying \"cm\" (cognitive model) objects 'Cm$new(formula, data, parspace)' R6 class underlying \"cm\" (cognitive model) objects 'Cm$new(formula, data, parspace)'","code":""},{"path":"/reference/Cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The R6 class underlying all ","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/Cm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The R6 class underlying all ","text":"parspace. optional define value makes parameter zero effect column called \"na\" parspace. example, parameter b b*x, -effect  setting b=0. -effect value can NA. fix Supplying list(alpha=0.5, beta=\"alpha\", gamma=NA) constrains parameters alpha, beta, gamma follows alpha=0.5: fix alpha 0.5. beta=\"alpha\": fix beta value alpha; alpha may free fixed model parameter parspace. delta=NA: ignore delta can ignored setting delta equal value column \"na\" parspace, given parspace value column \"na\" delta. can ignore model parameter setting NA 'fix', case 'parspace' needs contain value column na nullifying effect parameter.","code":""},{"path":[]},{"path":"/reference/Cm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The R6 class underlying all ","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/Cm.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"The R6 class underlying all ","text":"call call model title string, name model formula Calling formula, e.g., y ~ x1 + x2 + x3 models one response variable (y) given one three-attribute stimulus, y ~ x1 + x2 | z1 + z2 models response given two two-attribute stimuli attributes separated \"+\"\" stimuli separated \"|\". input Inputs model standardized form: three-dimensional matrix based formula data dimensions n(data) x n(attributes) x n(stimuli) more_input Additional inputs model variables part formula, three-dimensional matrix dimensions n(data) x n(additional inputs) x n(stimuli) res response variable modeled, two-dimensional matrix dimensions n(data) x n(response variables) natt List number attributes per stimulus nobs Number observations data nstim Number stimuli model input nres Number response variables ncon Number constraints parameter par Model parameters, named list fix Fixed model parameters, named list parspace Parameter space, matrix one parameter per row, four columns lb (lower bound), ub (upper bound), start (starting value fitting) na (value parameter effect model); rownames parameter names pred Model predictions data parnames Parameter names stimnames Stimuli names prednames Prediction column names > 1 prediction mode string modality predicted responses \"continuous\" \"discrete\" choicerule string choicerule model uses (e.g. \"softmax\"\") pred_types types predictios model males discount numeric trials discount fitting constraints object parameter constraints fitobj object holding results parameter fitting method options list options pass_checks logical, TRUE means model passes internal checks","code":""},{"path":[]},{"path":"/reference/Cm.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"The R6 class underlying all ","text":"Cm$new() Cm$fit() Cm$coef() Cm$predict() Cm$simulate() Cm$set_data() Cm$set_par() Cm$get_par() Cm$npar() Cm$gof() Cm$logLik() Cm$BIC() Cm$AIC() Cm$AICc() Cm$MSE() Cm$SSE() Cm$RMSE() Cm$set_lb() Cm$set_ub() Cm$set_start() Cm$print() Cm$summary() Cm$pargrid() Cm$getCall() Cm$clone()","code":""},{"path":"/reference/Cm.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"The R6 class underlying all ","text":"Initializes new model","code":""},{"path":"/reference/Cm.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$new(   formula,   data = NULL,   parspace = make_parspace(),   fix = NULL,   choicerule = if (grepl(\"^c\", mode)) {     \"none\" } else {     NULL },   title = NULL,   discount = NULL,   mode = NULL,   options = NULL )"},{"path":"/reference/Cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"formula formula, variables data modeled. example, y ~ x1 + x2 models response y function one stimulus features x1, x2. data data frame, data modeled. parspace (optional, required add model parameters) n x 4 matrix, parameter space. Use make_parspace construct . Column names must \"lb\",\"ub\",\"start\",\"na\", row names must parameter names. Columns contain lower limit, upper limit, starting value fitting, (optional) value makes parameter zero effect, can NA. See details. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names depend formula can delta, x1, x2 (see details - model parameters). list(x1 = 3.09) sets parameter x1 equal 3.09. list(x1 = \"x2\") sets parameter x1 equal parameter x2 (estimates x2). list(x2 = \"x1\", x1 = 3.09) sets parameter x2 equal parameter x1 sets x1 equal 3.09 (estimates none two). list(x1 = NA) omits parameter x1, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. choicerule string, choice rule. Allowed values, see  cm_choicerules(): \"none\" choice rule, \"softmax\" soft-maximum, \"luce\" Luce's axiom. title (optional, default class name) string, model's name. discount (optional) number, e.g. 10 ignores first ten data rows fitting parameters calculating goodness fits discount (optional) integer integer vector (default 0), ddefining many, starting trial 1, discount fitting. mode string, response mode. Allowed \"discrete\", `\"continuous\". Discrete responses binary (0 1), continuous responses numbers- options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options.","code":""},{"path":"/reference/Cm.html","id":"method-fit-","dir":"Reference","previous_headings":"","what":"Method fit()","title":"The R6 class underlying all ","text":"Fits free model parameters response data","code":""},{"path":"/reference/Cm.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$fit(solver = self$options$solver, measure = self$options$fit_measure, ...)"},{"path":"/reference/Cm.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"solver (optional) string model solver measure (optional) string goodness--fit measure solver optimizes (e.g. \"loglikelihood\"). Possible values, see type argument gof ... arguments","code":""},{"path":"/reference/Cm.html","id":"method-coef-","dir":"Reference","previous_headings":"","what":"Method coef()","title":"The R6 class underlying all ","text":"Returns free parameters model","code":""},{"path":"/reference/Cm.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$coef()"},{"path":"/reference/Cm.html","id":"method-predict-","dir":"Reference","previous_headings":"","what":"Method predict()","title":"The R6 class underlying all ","text":"Make predictions every row input data model","code":""},{"path":"/reference/Cm.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$predict(type = \"response\", newdata = NULL, ...)"},{"path":"/reference/Cm.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"type (optional, default \"response\") Type prediction make. See respective model. newdata (optional) data frame new data compute predictions. ... arguments (ignored) calls child model's make_prediction function every slice third dimension input matrix","code":""},{"path":"/reference/Cm.html","id":"method-simulate-","dir":"Reference","previous_headings":"","what":"Method simulate()","title":"The R6 class underlying all ","text":"Simulates observable data model","code":""},{"path":"/reference/Cm.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$simulate(newdata = NULL)"},{"path":"/reference/Cm.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"newdata (optional) data frame inputs (e.g., stimuli) used simulation","code":""},{"path":"/reference/Cm.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"The R6 class underlying all ","text":"matrix simulated choices judgment values","code":""},{"path":"/reference/Cm.html","id":"method-set-data-","dir":"Reference","previous_headings":"","what":"Method set_data()","title":"The R6 class underlying all ","text":"New data input cogscim","code":""},{"path":"/reference/Cm.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$set_data(data = NULL)"},{"path":"/reference/Cm.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"data data frame variables corresponding inputs model needs","code":""},{"path":"/reference/Cm.html","id":"method-set-par-","dir":"Reference","previous_headings":"","what":"Method set_par()","title":"The R6 class underlying all ","text":"Set model parameter","code":""},{"path":"/reference/Cm.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$set_par(x, check = TRUE, constrain = TRUE)"},{"path":"/reference/Cm.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"x named list parameters, names must parspace check (optional, default TRUE) logical value, TRUE parameter names checked validity, FALSE check performed. constrain (optional, default TRUE) logical, whether newly constrain parameters setting parameter constrained.","code":""},{"path":"/reference/Cm.html","id":"method-get-par-","dir":"Reference","previous_headings":"","what":"Method get_par()","title":"The R6 class underlying all ","text":"Get model parameter","code":""},{"path":"/reference/Cm.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$get_par(x = \"all\")"},{"path":"/reference/Cm.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"x (optional) string, set parameters get, \"\" returns parameter, \"free\" returns free parameters, \"constrained\" returns constrained parameters, \"equal\" returns parameters equal another parameter","code":""},{"path":"/reference/Cm.html","id":"method-npar-","dir":"Reference","previous_headings":"","what":"Method npar()","title":"The R6 class underlying all ","text":"Number model parameters","code":""},{"path":"/reference/Cm.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$npar(x = \"free\")"},{"path":"/reference/Cm.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"x string, parameters return, allowed \"\", \"free\", \"constrained\", \"equal\"","code":""},{"path":"/reference/Cm.html","id":"method-gof-","dir":"Reference","previous_headings":"","what":"Method gof()","title":"The R6 class underlying all ","text":"Computes goodness model fit","code":""},{"path":"/reference/Cm.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$gof(   type = self$options$fit_measure,   n = self$options$fit_args$n,   newdata = NULL,   discount = (length(self$discount) > 0),   ... )"},{"path":"/reference/Cm.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"type string, goodness fit measure use, e.g. \"loglikelihood\"; allowed values see gof n (optional) fitting aggregate data, supply many raw data points underly aggregated data point newdata (optional) data frame new data - experimental! discount (optional) number, e.g. 10 ignores first ten data rows fitting parameters calculating goodness fits discount (optional) integer integer vector (default 0), ddefining many, starting trial 1, discount fitting. ... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-loglik-","dir":"Reference","previous_headings":"","what":"Method logLik()","title":"The R6 class underlying all ","text":"Log likelihood observed responses model predictions","code":""},{"path":"/reference/Cm.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$logLik(...)"},{"path":"/reference/Cm.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-bic-","dir":"Reference","previous_headings":"","what":"Method BIC()","title":"The R6 class underlying all ","text":"Bayesian Information Criterion model predictions given observed responses","code":""},{"path":"/reference/Cm.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$BIC(...)"},{"path":"/reference/Cm.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-aic-","dir":"Reference","previous_headings":"","what":"Method AIC()","title":"The R6 class underlying all ","text":"Akaike Information Criterion model predictions given observed response","code":""},{"path":"/reference/Cm.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$AIC(...)"},{"path":"/reference/Cm.html","id":"arguments-11","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-aicc-","dir":"Reference","previous_headings":"","what":"Method AICc()","title":"The R6 class underlying all ","text":"Small-sample corrected Akaike Information Criterion model predictions given responses","code":""},{"path":"/reference/Cm.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$AICc(...)"},{"path":"/reference/Cm.html","id":"arguments-12","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-mse-","dir":"Reference","previous_headings":"","what":"Method MSE()","title":"The R6 class underlying all ","text":"Mean squared error model predictions given observed responses","code":""},{"path":"/reference/Cm.html","id":"usage-14","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$MSE(...)"},{"path":"/reference/Cm.html","id":"arguments-13","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-sse-","dir":"Reference","previous_headings":"","what":"Method SSE()","title":"The R6 class underlying all ","text":"Sum squared errors model predictions given observed responses","code":""},{"path":"/reference/Cm.html","id":"usage-15","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$SSE(...)"},{"path":"/reference/Cm.html","id":"arguments-14","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-rmse-","dir":"Reference","previous_headings":"","what":"Method RMSE()","title":"The R6 class underlying all ","text":"Root mean squared error model predictions observed responses","code":""},{"path":"/reference/Cm.html","id":"usage-16","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$RMSE(...)"},{"path":"/reference/Cm.html","id":"arguments-15","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... arguments (ignored)","code":""},{"path":"/reference/Cm.html","id":"method-set-lb-","dir":"Reference","previous_headings":"","what":"Method set_lb()","title":"The R6 class underlying all ","text":"Change lower limit parameter values","code":""},{"path":"/reference/Cm.html","id":"usage-17","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$set_lb(...)"},{"path":"/reference/Cm.html","id":"arguments-16","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... new parameter bound, e.g. alpha = 0 sets lower bound parameter alpha 0","code":""},{"path":"/reference/Cm.html","id":"method-set-ub-","dir":"Reference","previous_headings":"","what":"Method set_ub()","title":"The R6 class underlying all ","text":"Change upper limit parameter values","code":""},{"path":"/reference/Cm.html","id":"usage-18","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$set_ub(...)"},{"path":"/reference/Cm.html","id":"arguments-17","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... new parameter bound, e.g. alpha = 0 sets lower bound parameter alpha 0","code":""},{"path":"/reference/Cm.html","id":"method-set-start-","dir":"Reference","previous_headings":"","what":"Method set_start()","title":"The R6 class underlying all ","text":"Change starting values fitting parameters","code":""},{"path":"/reference/Cm.html","id":"usage-19","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$set_start(...)"},{"path":"/reference/Cm.html","id":"arguments-18","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"... new parameter bound, e.g. alpha = 0 sets lower bound parameter alpha 0","code":""},{"path":"/reference/Cm.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"The R6 class underlying all ","text":"Prints model object","code":""},{"path":"/reference/Cm.html","id":"usage-20","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$print(digits = 2)"},{"path":"/reference/Cm.html","id":"arguments-19","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"digits number specifying number digits print","code":""},{"path":"/reference/Cm.html","id":"method-summary-","dir":"Reference","previous_headings":"","what":"Method summary()","title":"The R6 class underlying all ","text":"Summarizes model, parameters, fit information","code":""},{"path":"/reference/Cm.html","id":"usage-21","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$summary()"},{"path":"/reference/Cm.html","id":"method-pargrid-","dir":"Reference","previous_headings":"","what":"Method pargrid()","title":"The R6 class underlying all ","text":"Produces parameter grid","code":""},{"path":"/reference/Cm.html","id":"usage-22","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$pargrid(nsteps = NULL, offset = NULL, par = NULL)"},{"path":"/reference/Cm.html","id":"arguments-20","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"nsteps list steps parameter offset number offset parameters bounds par (optional) vector parameter names generate grid.","code":""},{"path":"/reference/Cm.html","id":"method-getcall-","dir":"Reference","previous_headings":"","what":"Method getCall()","title":"The R6 class underlying all ","text":"Retrieves call Remove choicerule","code":""},{"path":"/reference/Cm.html","id":"usage-23","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$getCall()"},{"path":"/reference/Cm.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"The R6 class underlying all ","text":"objects class cloneable method.","code":""},{"path":"/reference/Cm.html","id":"usage-24","dir":"Reference","previous_headings":"","what":"Usage","title":"The R6 class underlying all ","text":"","code":"Cm$clone(deep = FALSE)"},{"path":"/reference/Cm.html","id":"arguments-21","dir":"Reference","previous_headings":"","what":"Arguments","title":"The R6 class underlying all ","text":"deep Whether make deep clone.","code":""},{"path":"/reference/Cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The R6 class underlying all ","text":"","code":"# No examples yet."},{"path":"/reference/cm_choicerules.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the Choicerules for Discrete Cognitive Models — cm_choicerules","title":"Show the Choicerules for Discrete Cognitive Models — cm_choicerules","text":"Show Choicerules Discrete Cognitive Models","code":""},{"path":"/reference/cm_choicerules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the Choicerules for Discrete Cognitive Models — cm_choicerules","text":"","code":"cm_choicerules(msg)"},{"path":"/reference/cm_choicerules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the Choicerules for Discrete Cognitive Models — cm_choicerules","text":"msg Logical, print header message, FALSE prints message.","code":""},{"path":"/reference/cm_choicerules.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the Choicerules for Discrete Cognitive Models — cm_choicerules","text":"","code":"cm_choicerules() #>  #> Available choice rules: #> [1] \"argmax\"  \"epsilon\" \"luce\"    \"softmax\""},{"path":"/reference/cm_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Advanced Options for Cognitive Models — cm_options","title":"Advanced Options for Cognitive Models — cm_options","text":"Advanced Options Cognitive Models","code":""},{"path":"/reference/cm_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Advanced Options for Cognitive Models — cm_options","text":"","code":"cm_options(   lb = NULL,   ub = NULL,   start = NULL,   fit = TRUE,   fit_measure = \"loglikelihood\",   fit_args = list(),   fit_data = NULL,   solver = \"auto\",   solver_args = list() )"},{"path":"/reference/cm_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Advanced Options for Cognitive Models — cm_options","text":"lb Named numeric vector, minimum values parameter may take: c(k = -10) lets parameter k start -10. ub Named numeric vector, maximum value parameters may take: c(k = 10) lets parameter k go 10. start Named numeric vector, start value parameters: c(k = 5) lets parameter k  start 5 optimiuation. fit Logical (default TRUE), FALSE disables parameter fitting. Useful testing models. fit_measure string (default \"loglikelihood\"), goodnes fit measure optimized parameter estimation. Can one types function cognitiveutils::gof(): \"loglikelihood\". Uses binomial PDF models discrete data. Uses normal PDF \\(N(\\mu, \\sigma)\\) models continuous data: \\(\\mu\\)=predictions, \\(\\sigma\\)=constant, estimated additional free paramter. change PDF set fit_args = list(pdf = \"xxx\") \"mse\" mean-squared error \"accuracy\" percent accuracy fit_args named list, additional arguments fitting, can arguments function cognitiveutils::gof(), list(n = 30) assumes row data mean 30 observations. Useful fit aggregated data. list(pdf = \"multinom\") uses multinomial PDF log-likelihood list(pdf = \"truncnorm\", = 0, b = 1) uses truncated normal PDF log-likelihood fit_data data frame, data estimate model parameters . Needed data parameter estimation differs data main data argument model. solver string, alorithm optinize free parameters. Run cm_solvers() list options. Changing may cause warnings ignored options may cause parameter bounds ignored model fail. Examples: \"grid\" uses grid search regular grid \"solnp\" uses solnp ... 21 solvers \"optimx\", \"nloptr\", \"nlminb\" ROI, see ROI::ROI_available_solvers() c(\"grid\", \"xxx\") uses grid-plus-optimization, xxx solver: grid search, followed optimization xxx using n best solutions start values optimization; overal best parameter result wins; n can set changing solver_args$nbest. solver_args (optional) list, additional arguments passed directly optimization solver list(offset = ) small number offset parameters boundaries solver = \"grid\". list(nsteps = ) number, number steps parameter regular grid, solver = \"grid\"). list(nbest = ) Number best solutions used starting values grid-plus-optimization, solver = c(\"grid\", \"xxx\"). list(control = ) control arguments solver (solnp)Rsolnp::solnp() ROI solvers","code":""},{"path":"/reference/cm_solvers.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the Optimization Solvers for Cognitive Models — cm_solvers","title":"Show the Optimization Solvers for Cognitive Models — cm_solvers","text":"Show Optimization Solvers Cognitive Models","code":""},{"path":"/reference/cm_solvers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the Optimization Solvers for Cognitive Models — cm_solvers","text":"","code":"cm_solvers(msg)"},{"path":"/reference/cm_solvers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the Optimization Solvers for Cognitive Models — cm_solvers","text":"msg Logical, print header message, FALSE prints message.","code":""},{"path":"/reference/cm_solvers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the Optimization Solvers for Cognitive Models — cm_solvers","text":"","code":"cm_solvers() #>  #> Available optimization solvers: #>  [1] \"alabama\"           \"auto\"              \"cbc\"               #>  [4] \"cccp\"              \"clp\"               \"cplex\"             #>  [7] \"deoptim\"           \"ecos\"              \"glpk\"              #> [10] \"grid\"              \"gurobi\"            \"ipop\"              #> [13] \"lpsolve\"           \"mosek\"             \"msbinlp\"           #> [16] \"neos\"              \"nlminb\"            \"nloptr.auglag\"     #> [19] \"nloptr.bobyqa\"     \"nloptr.cobyla\"     \"nloptr.crs2lm\"     #> [22] \"nloptr.direct\"     \"nloptr.directL\"    \"nloptr.isres\"      #> [25] \"nloptr.lbfgs\"      \"nloptr.lbfgs\"      \"nloptr.mma\"        #> [28] \"nloptr.neldermead\" \"nloptr.newuoa\"     \"nloptr.sbplx\"      #> [31] \"nloptr.slsqp\"      \"nloptr.stogo\"      \"nloptr.tnewton\"    #> [34] \"nloptr.varmetric\"  \"optimx\"            \"qpoases\"           #> [37] \"quadprog\"          \"scs\"               \"solnp\"             #> [40] \"symphony\""},{"path":"/reference/cognitivemodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Add components to a model — cognitivemodel","title":"Add components to a model — cognitivemodel","text":"cogscimodel() initializes cogscimodel object. can used declare input data used model.","code":""},{"path":"/reference/cognitivemodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add components to a model — cognitivemodel","text":"","code":"cognitivemodel(data, ...)"},{"path":"/reference/cognitivemodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add components to a model — cognitivemodel","text":"data data.frame holding variables first model uses","code":""},{"path":"/reference/cognitivemodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add components to a model — cognitivemodel","text":"cogscimodel() used construct initial model object, almost always followed %+% add component model.","code":""},{"path":"/reference/cognitivemodels-package.html","id":null,"dir":"Reference","previous_headings":"","what":"cognitivemodels: Cognitive Models - Estimation, Prediction, and Development of Models for Cognitive Scientists — cognitivemodels-package","title":"cognitivemodels: Cognitive Models - Estimation, Prediction, and Development of Models for Cognitive Scientists — cognitivemodels-package","text":"Implementation cognitive models, includes general class cognitive models methods fit free parameters data , can apply choicerules, various goodness--fit measures (loglikelihood, MSE, etc.). interface similar lm() interface.","code":""},{"path":"/reference/cognitivemodels-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cognitivemodels: Cognitive Models - Estimation, Prediction, and Development of Models for Cognitive Scientists — cognitivemodels-package","text":"following cogniitve models part packge: baseline - constant 1/N choice models (sanity check) bayes - cognitive bayesian updating model cpt - cummulative prospect theory (Tversky & Kahneman, 1992) ebm - exemplar-based models hm1988 - Houston & McNamara's optimal model risk-sensitive foraging lwei - linear weighting model rscpt - risk-sensitive-foraging cpt model rsfft - risk-sensitive foraging fast frugal tree utility - utility models","code":""},{"path":"/reference/constraints.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the constraints of a cognitive model — constraints","title":"Show the constraints of a cognitive model — constraints","text":"constraints(x) prints parameter constraints cognitive model named x nicely formatted","code":""},{"path":"/reference/constraints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the constraints of a cognitive model — constraints","text":"","code":"constraints(x, ...)  # S3 method for cm constraints(x, ...)"},{"path":"/reference/constraints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the constraints of a cognitive model — constraints","text":"x model object class cm ... arguments (ignored)","code":""},{"path":"/reference/constraints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the constraints of a cognitive model — constraints","text":"","code":"D <- data.frame(x = 1, y = 1, z = 1) M <- bayes_beta(y ~ x + z, D, fix = \"start\") #> Error in bayes_beta(y ~ x + z, D, fix = \"start\"): could not find function \"bayes_beta\" constraints(M)    # view the parspace #> Error in constraints(M): object 'M' not found"},{"path":"/reference/cpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Prospect Theory Models — cpt","title":"Cumulative Prospect Theory Models — cpt","text":"Fits cumulative prospect theory, CPT (Tversky & Kahneman, 1992). cpt_d() fits CPT discrete responses = choices. cpt_c() fits CPT continuous responses = utility values. cpt_mem_d() fits CPT editing step based memory discrete responses = choices (Thaler & Johnson, 1990). cpt_mem_c() fits CPT editing step based memory continuous responses = utility values (Thaler & Johnson, 1990).","code":""},{"path":"/reference/cpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Prospect Theory Models — cpt","text":"","code":"cpt_d(   formula,   data,   choicerule,   ref = 0L,   fix = list(),   weighting = c(\"TK1992\"),   value = c(\"TK1992\"),   options = NULL )  cpt_c(   formula,   data,   ref = 0L,   fix = list(),   weighting = c(\"TK1992\"),   value = c(\"TK1992\"),   options = NULL )  cpt_mem_d(   formula,   mem,   data,   fix = list(),   choicerule,   editing = \"hedonic\",   weighting = c(\"TK1992\"),   value = c(\"TK1992\"),   options = NULL )  cpt_mem_c(   formula,   mem,   data,   fix = list(),   editing = \"hedonic\",   weighting = c(\"TK1992\"),   value = c(\"TK1992\"),   options = NULL )"},{"path":"/reference/cpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Prospect Theory Models — cpt","text":"formula formula, variables data modeled. example, y ~ x1 + p2 + x3 + p4 | x5 + p6 + x7 + p8 models response y function two stimuli features x1, p2, x3, p4 x5, p6, x7, p8, alternating outcomes x probabilities p (respectively). Lines | separate stimuli. data data frame, data modeled. choicerule string, choice rule. Allowed values, see  cm_choicerules(): \"none\" choice rule, \"softmax\" soft-maximum, \"luce\" Luce's axiom. ref (optional, default: 0) number, string, RHS formula, reference point variable data holds reference point. example ~ ref. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names alpha, beta, gammap, gamman, lambda (see details - model parameters). list(alpha = 1.08) sets parameter alpha equal 1.08. list(alpha = \"beta\") sets parameter alpha equal parameter beta (estimates beta). list(beta = \"alpha\", alpha = 1.08) sets parameter beta equal parameter alpha sets alpha equal 1.08 (estimates none two). list(alpha = NA) omits parameter alpha, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. weighting (optional) string, name probability weighting function, allowed \"KT1992\" weighting Kahneman & Tversky (1992) NA weighting. value (optional) string, name value function. Allowed \"KT1992\" value function Kahneman & Tversky (1992) NA value transformation. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. mem (optional, default: 0) number, string, RHS formula, prior gains losses memory. Formula string refer variables data, example ~ xoutc. editing (optional) string, editing rule use (see Thaler & Johnson, 1999, pp. 645), currently \"hedonic\". discount number, many initial trials use parameter fitting. ... arguments, ignored.","code":""},{"path":"/reference/cpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Prospect Theory Models — cpt","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/cpt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Prospect Theory Models — cpt","text":"Fits cumulative prospect theory.","code":""},{"path":"/reference/cpt.html","id":"parameter-space","dir":"Reference","previous_headings":"","what":"Parameter Space","title":"Cumulative Prospect Theory Models — cpt","text":"model following free parameters: alpha utility exponent positive outcomes. beta utility exponent negative outcomes. gammap probability distortion positive outcomes. gamman utility exponent negative outcomes. lambda loss aversion. cpt_d() cpt_mem_d(): choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing..","code":""},{"path":"/reference/cpt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Prospect Theory Models — cpt","text":"Tversky, ., & Kahneman, D. (1992). Advances prospect theory: cumulative representation uncertainty. Journal Risk Uncertainty, 5, 297–-323. doi:10.1007/BF00122574 Thaler, R. H., & Johnson, E. J. (1990). Gambling House Money Trying Break Even: Effects Prior Outcomes Risky Choice. Management Science, 36(6), 643--660. doi:10.1287/mnsc.36.6.643","code":""},{"path":[]},{"path":"/reference/cpt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Prospect Theory Models — cpt","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/cpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Prospect Theory Models — cpt","text":"","code":"## From Tversky, A., & Kahneman, D. (1992). dt <- data.frame(   x1 = c(100, -100),   px = 1,   x2 = 0,   y1 = c(200, -200),   py = c(.71,.64),   y2 = 0,   rp = 1)  # Make the model ------------------------------------------- # add fix parameters (don't fit) # using the Parameter from the paper  # Discrete responses with choicerule M <- cpt_d(rp ~ x1 + px + x2 | y1 + py + y2, ref = 0,          choicerule = \"softmax\", data = dt,          fix = list(alpha = 0.88, beta = 0.88, lambda = 2.25,          gammap = 0.61, gamman = 0.69, tau = 1)) #> Fitting free parameters [tau] by maximizing loglikelihood (binomial pdf) with grid, solnp. # View the model M        # has a parameter `tau` #> CPT (TK1992) | choice rule: softmax #> Call: #> cpt_d(formula = rp ~ x1 + px + x2 | y1 + py + y2, data = dt,  ... #>  #> Free parameters: estimates  #>   tau   #> 0.016   #>  #> Constrained and fixed parameters: #>  alpha    beta  gammap  gamman  lambda   #>   0.88    0.88    0.61    0.69    2.25   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.)  # Continuous responses/utility M <- cpt_c(rp ~ x1 + px + x2 | y1 + py + y2, ref = 0,          data = dt,          fix = list(alpha = 0.88, beta = 0.88, lambda = 2.25,          gammap = 0.61, gamman = 0.69)) #> Fitting free parameters [sigma] by maximizing loglikelihood (normal pdf) with grid, solnp. #> Warning:  #> solnp-->warning: Equal Lower/Upper Bounds Found. Consider #>  #> \t\t\t\t\t\texcluding fixed parameters. #> No optimal parameters found. The solver did not converge. #> NULL # View the model M        # No parameter `tau` #> CPT (TK1992) | choice rule: none #> Call: #> cpt_c(formula = rp ~ x1 + px + x2 | y1 + py + y2, data = dt,  ... #>  #> Free parameters: estimates (NOT CONVERGED! see m$fitobj$status)  #> sigma   #> -0.05   #>  #> Constrained and fixed parameters: #>  alpha    beta  gammap  gamman  lambda   #>   0.88    0.88    0.61    0.69    2.25   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.)  # Methods --------------------------------------------------- predict(M, \"value\") # predict values, also: M$predict(\"value\") #> Error in private$get_input(f = self$formula, d = newdata, ...): Can't find variables from 'formula' in 'data': [x1, px, x2, I(1 - px), y1, py, y2, I(1 - py)]. predict(M, \"mode\") # predict choice probability after softmax #> Error in private$get_input(f = self$formula, d = newdata, ...): Can't find variables from 'formula' in 'data': [x1, px, x2, I(1 - px), y1, py, y2, I(1 - py)]. summary(M) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #>  #> Model: #>   with no choice rule #> Call: #> rp ~ x1 + px + x2 + I(1 - px) | y1 + py + y2 + I(1 - py) #>  #> (Constrained) Parameters: #>          Estimate #> (alpha)  0.88     #> (beta)   0.88     #> (gammap) 0.61     #> (gamman) 0.69     #> (lambda) 2.25     #> sigma    -0.05    #>  #> Fit Measures: #> MSE: 10110, LL: NaN, AIC: NaN, BIC: NaN #>  anova(M) #> Sum Sq. Table #>  N Par Sum Sq Mean Sq #>      1  20221   10110"},{"path":"/reference/cpttest.html","id":null,"dir":"Reference","previous_headings":"","what":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","title":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","text":"Data risky choices test parameter estimation method model.","code":""},{"path":"/reference/cpttest.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","text":"object class \"data.table\"; see data.table::fread().","code":""},{"path":"/reference/cpttest.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","text":"Glöckner, ., & Pachur, T. (2012). Cognitive models risky choice: Parameter stability predictive accuracy prospect theory. Cognition, 123(1), 21–32. doi:10.1016/j.cognition.2011.12.002","code":""},{"path":"/reference/cpttest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","text":"Glöckner, ., & Pachur, T. (2012). Cognitive models risky choice: Parameter stability predictive accuracy prospect theory. Cognition, 123(1), 21–32. doi:10.1016/j.cognition.2011.12.002","code":""},{"path":"/reference/cpttest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test data for fitting the Cumulative Prospect Theory, cpt, model — cpttest","text":"","code":"data(cpttest)"},{"path":"/reference/dot-grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a regular or random grid — .grid","title":"Make a regular or random grid — .grid","text":"Make regular random grid","code":""},{"path":"/reference/dot-grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a regular or random grid — .grid","text":"","code":".grid(rsum, ncol, nrow, regular = TRUE, nstep = NULL, offset = 0)"},{"path":"/reference/dot-grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a regular or random grid — .grid","text":"rsum row sums ncol number columns nrow number rows (auto-determines) regular regular, FALSE means random nstep number steps, e.g. 4 0, 0.25, 0.5, 0.75, 1 offset adjust max min minus value","code":""},{"path":"/reference/dot-solve_grid_constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds the parameter that are constrained to the free parameters in the construction of a grid — .solve_grid_constraint","title":"Adds the parameter that are constrained to the free parameters in the construction of a grid — .solve_grid_constraint","text":"Adds parameter constrained free parameters construction grid","code":""},{"path":"/reference/dot-solve_grid_constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds the parameter that are constrained to the free parameters in the construction of a grid — .solve_grid_constraint","text":"","code":".solve_grid_constraint(fix, con)"},{"path":"/reference/dot-solve_grid_constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds the parameter that are constrained to the free parameters in the construction of a grid — .solve_grid_constraint","text":"fix named vector values parameters grid con obect type L_constraint csm_constraint, constraint stored model","code":""},{"path":"/reference/ebm.html","id":null,"dir":"Reference","previous_headings":"","what":"Exemplar-based Cognitive Models — ebm","title":"Exemplar-based Cognitive Models — ebm","text":"ebm() fits exemplar-based model. gcm() fits generalized context model (aka. exemplar model) discrete responses (Medin & Schaffer, 1978; Nosofsky, 1986) ebm_j() fits exemplar-based judgment model continuous responses (Juslin et al., 2003)","code":""},{"path":"/reference/ebm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exemplar-based Cognitive Models — ebm","text":"","code":"gcm(   formula,   class,   data,   choicerule,   fix = NULL,   options = NULL,   similarity = \"minkowski\",   ... )  ebm_j(   formula,   criterion,   data,   fix = NULL,   options = NULL,   similarity = \"minkowski\",   ... )  mem(formula, criterion, data, choicerule, options = NULL, ...)  ebm(formula, criterion, data, mode, fix = NULL, options = NULL, ...)"},{"path":"/reference/ebm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exemplar-based Cognitive Models — ebm","text":"formula formula, variables data modeled. example, y ~ x1 + x2 | x3 + x4 models response y function two stimuli features x1, x2 x3, x4 (respectively). Lines | separate stimuli. class formula, variable data feedback true class/category. example ~ cat. NAs interpreted trials without feedback (partial feedback, see details). data data frame, data modeled. choicerule string, choice rule. Allowed values, see  cm_choicerules(): \"none\" choice rule, \"softmax\" soft-maximum, \"luce\" Luce's axiom. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names depend formula, class can x1, x2, lambda, r, q, b0, b1 (see details - model parameters). list(r = 2.70) sets parameter r equal 2.70. list(r = \"q\") sets parameter r equal parameter q (estimates q). list(q = \"r\", r = 2.70) sets parameter q equal parameter r sets r equal 2.70 (estimates none two). list(r = NA) omits parameter r, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. similarity (optional) string, similarity function, currently \"minkowski\". ... arguments, ignored. criterion formula, variable data feedback continous criterion. example, ~ val NAs interpreted trials without feedback (partial feedback, see details). mode (optional) string, response mode, can \"discrete\" \"continuous\", can abbreviated. missing, inferred criterion. discount number, many initial trials use parameter fitting.","code":""},{"path":"/reference/ebm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exemplar-based Cognitive Models — ebm","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/ebm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exemplar-based Cognitive Models — ebm","text":"model can predict new data - predict(m, newdata = ...) - works: newdatas criterion class variable NAs, model predicts using originally supplied data exemplar-memory. Parameters re-fit. newdata's' criterion class variable values NA, model predicts first row newdata using originally-supplied data exemplars memory, predictions subsequent rows newdata use also criterion values new data. words, exemplar memory extended exemplars new data criterion exists. Parameters re-fit.","code":""},{"path":"/reference/ebm.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Exemplar-based Cognitive Models — ebm","text":"model following free parameters, depending model specification (see npar()). model formula ~ x1 + x2 parameters: x1, x2 (dynamic names) attention weights, names correspond right side formula. lambda sensitivity, larger values make similarity decrease steeply higher distance metric. r order Minkowski distance metric (2 Euclidean metric, 1 city-block metric). q shape relation similarity distance, usually equal r. gcm(): b0, b1 (dynamic names) bias towards categories, names b plus unique values class. example b0 bias class = 0. choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":"/reference/ebm.html","id":"partial-feedback","dir":"Reference","previous_headings":"","what":"Partial Feedback","title":"Exemplar-based Cognitive Models — ebm","text":"Regarding NA values class criterion: model takes NA values class/criterion variable trials without feedback, stimulus shown feedback class criterion given (partial feedback paradigm). model predicts class criterion trials without feedback based previous exemplar(s) feedback shown. model ignores trials without feedback prediction subsequent trials.","code":""},{"path":"/reference/ebm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exemplar-based Cognitive Models — ebm","text":"Medin, D. L., & Schaffer, M. M. (1978). Context theory classification learning. Psychological Review, 85, 207-238. http://dx.doi.org/10.1037//0033-295X.85.3.207 Nosofsky, R. M. (1986). Attention, similarity, identification-categorization relationship. Journal Experimental Psychology: General, 115, 39-57. http://dx.doi.org/10.1037/0096-3445.115.1.39 Juslin, P., Olsson, H., & Olsson, .-C. (2003). Exemplar effects categorization multiple-cue judgment. Journal Experimental Psychology: General, 132, 133-156. http://dx.doi.org/10.1037/0096-3445.132.1.133","code":""},{"path":[]},{"path":"/reference/ebm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Exemplar-based Cognitive Models — ebm","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/ebm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exemplar-based Cognitive Models — ebm","text":"","code":"# Make some fake data D <- data.frame(f1 = c(0,0,1,1,2,2,0,1,2),     # feature 1                 f2 = c(0,1,2,0,1,2,0,1,2),     # feature 2                 cl = c(0,1,0,0,1,0,NA,NA,NA),  # criterion/class                  y = c(0,0,0,1,1,1,0,1,1))     # participant's responses  M <- gcm(y ~ f1+f2, class= ~cl, D, fix=\"start\",          choicerule = \"none\")                  # GCM, par. fixed to start val.  predict(M)                                     # predict 'pred_f', pr(cl=1 | features, trial) #> [1] 0.5000000 0.0000000 0.6123276 0.3228975 0.2359031 0.4526775 0.3258317 #> [8] 0.3598675 0.3258317 M$predict()                                    # -- (same) -- #> [1] 0.5000000 0.0000000 0.6123276 0.3228975 0.2359031 0.4526775 0.3258317 #> [8] 0.3598675 0.3258317 summary(M)                                     # summary #>  #> Model: #>   with no choice rule #> Call: #> y ~ f1 + f2 #>  #> No Free Parameters #>  #> Fit Measures: #> MSE: 0.33, LL: -7.5, AIC: 15, BIC: 15 #>  anova(M)                                       # anova-like table #> Sum Sq. Table #>  N Par Sum Sq Mean Sq #>      0 2.9373 0.32636 logLik(M)                                      # Log likelihood #> 'log Lik.' -7.545741 (df=0) M$logLik()                                     # -- (same) -- #> 'log Lik.' -7.545741 (df=0) M$MSE()                                        # mean-squared error #> [1] 0.326362 M$npar()                                       # 7 parameters #> [1] 0 M$get_par()                                    # parameter values #>     f1     f2 lambda      r      q     b0     b1  #>    0.5    0.5    0.5    1.5    1.5    0.5    0.5  M$coef()                                       # 0 free parameters #> NULL   ### Specify models # ------------------------------- gcm(y ~ f1 + f2, class = ~cl, D,      choicerule = \"none\")                          # GCM (has bias parameter) #> Fitting free parameters [f1, lambda, r, q, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\") #>  #> Free parameters: estimates  #>     f1  lambda       r       q      b0   #>  0.001   0.001   1.000   1.000   0.175   #>  #> Constrained and fixed parameters: #>   f2    b1   #> 1.00  0.82   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) ebm(y~f1+f2, criterion=~cl, D, mode=\"discrete\",     choicerule = \"none\")                          # -- (same) -- #> Fitting free parameters [f1, lambda, r, q, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> Exemplar model - multiplicative - minkowski | choice rule: none #> Call: #> ebm(formula = y ~ f1 + f2, criterion = ~cl, data = D, mode = \"discrete\",  ... #>  #> Free parameters: estimates  #>     f1  lambda       r       q      b0   #>  0.001   0.001   1.000   1.000   0.175   #>  #> Constrained and fixed parameters: #>   f2    b1   #> 1.00  0.82   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) ebm_j(y ~ f1 + f2, criterion = ~cl, D)              # Judgment EBM  (no bias par.) #> Fitting free parameters [f1, lambda, r, q] by minimizing mse with solnp. #> Exemplar-based judgment - multiplicative - minkowski | choice rule: none #> Call: #> ebm_j(formula = y ~ f1 + f2, criterion = ~cl, data = D) #>  #> Free parameters: estimates  #>     f1  lambda       r       q   #>  0.001   0.523   1.000   1.000   #>  #> Constrained and fixed parameters: #>   f2   #>    1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) ebm(y~f1+f2, criterion=~cl, D, mode=\"continuous\")   # -- (same) -- #> Fitting free parameters [f1, lambda, r, q] by minimizing mse with solnp. #> Exemplar model - multiplicative - minkowski | choice rule: none #> Call: #> ebm(formula = y ~ f1 + f2, criterion = ~cl, data = D, mode = \"continuous\") #>  #> Free parameters: estimates  #>     f1  lambda       r       q   #>  0.001   0.523   1.000   1.000   #>  #> Constrained and fixed parameters: #>   f2   #>    1   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.)   ### Specify parameter estimation # ------------------------------- gcm(y~f1+f2, ~cl, D, fix=list(b0=0.5, b1=0.5),      choicerule = \"none\")                       # fix 'bias' par. to 0.5, fit 5 par #> Fitting free parameters [f1, lambda, r, q] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Free parameters: estimates  #>     f1  lambda       r       q   #>  0.001   0.493   1.000   1.000   #>  #> Constrained and fixed parameters: #>   f2    b0    b1   #>  1.0   0.5   0.5   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) gcm(y~f1+f2, ~cl, D, fix=list(f1=0.9,f2=0.1),      choicerule = \"none\")                       # fix attention 'f1' to 90 %  f1 & fit 5 par #> Fitting free parameters [lambda, r, q, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Free parameters: estimates  #> lambda       r       q      b0   #>  0.001   1.524   1.000   0.175   #>  #> Constrained and fixed parameters: #>   f1    f2    b1   #> 0.90  0.10  0.82   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) gcm(y~f1+f2, ~cl, D, fix=list(q=2, r=2),      choicerule = \"none\")                      # fix 'q', 'q' to 2 & fit 5 par #> Fitting free parameters [f1, lambda, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Free parameters: estimates  #>     f1  lambda      b0   #>  0.999   0.001   0.175   #>  #> Constrained and fixed parameters: #>    f2      r      q     b1   #> 0.001  2.000  2.000  0.825   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) gcm(y~f1+f2, ~cl, D, fix=list(q=1, r=1),      choicerule = \"none\")                      # fix 'q', 'r' to 1 & fit 5 par #> Fitting free parameters [f1, lambda, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Free parameters: estimates  #>     f1  lambda      b0   #>  0.001   0.001   0.175   #>  #> Constrained and fixed parameters: #>   f2     r     q    b1   #> 1.00  1.00  1.00  0.82   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) gcm(y~f1+f2, ~cl, D, fix=list(lambda=2),      choicerule = \"none\")                      # fix 'lambda' to 2 & fit 6 par #> Fitting free parameters [f1, r, q, b0] by maximizing loglikelihood (binomial pdf) with solnp. #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Free parameters: estimates  #>   f1     r     q    b0   #> 0.52  1.00  1.00  0.16   #>  #> Constrained and fixed parameters: #>     f2  lambda      b1   #>   0.48    2.00    0.84   #>  #> --- #> Note:  View constraints by constraints(.), view parameter space by parspace(.) gcm(y~f1+f2, ~cl, D, fix=\"start\",      choicerule = \"none\")                        # fix all par to start val.  #> GCM - multiplicative - minkowski | choice rule: none #> Call: #> gcm(formula = y ~ f1 + f2, class = ~cl, data = D, choicerule = \"none\",  ... #>  #> Constrained and fixed parameters: #>     f1      f2  lambda       r       q      b0      b1   #>    0.5     0.5     0.5     1.5     1.5     0.5     0.5   #>  #> --- #> Note:  No free parameters. View constraints by constraints(.), view parameter space by parspace(.)"},{"path":"/reference/ebm_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Predictions for the Exemplar-based Models (GCM, EBM) — ebm_cpp","title":"Computes Predictions for the Exemplar-based Models (GCM, EBM) — ebm_cpp","text":"Computes Predictions Exemplar-based Models (GCM, EBM)","code":""},{"path":"/reference/ebm_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Predictions for the Exemplar-based Models (GCM, EBM) — ebm_cpp","text":"","code":"ebm_cpp(   criterion,   features,   w,   r,   q,   lambda,   b,   wf,   lastLearnTrial,   firstOutTrial,   init,   has_criterion,   similarity,   ismultiplicative )"},{"path":"/reference/ebm_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Predictions for the Exemplar-based Models (GCM, EBM) — ebm_cpp","text":"criterion numeric vector experienced criterion features numeric matrix feature criterion w numeric vector weights (model parameter) r order Minkowski distance metic (model parameter) q relation similarity distance (model parameter) lambda sensitivity (model parameter) b bias parameter vector classification (model parameter), must NA judgments wf weight vector weight feature combination lastLearnTrial integer last trial learning phase firstOutTrial integer first trial output, starting predictions later init value initial trials has_criterion vector criterion present similarity string, similarity function ismultiplicative number (0 1), 1 means combination exemplars multiplicative, .e. multiplicative exemplar model","code":""},{"path":"/reference/ebm_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes Predictions for the Exemplar-based Models (GCM, EBM) — ebm_cpp","text":"","code":"# none"},{"path":"/reference/end.html","id":null,"dir":"Reference","previous_headings":"","what":"Ends building a cognitivemodel via + — end","title":"Ends building a cognitivemodel via + — end","text":"Ends building cognitivemodel via +","code":""},{"path":"/reference/end.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ends building a cognitivemodel via + — end","text":"","code":"end(obj, ...)"},{"path":"/reference/end.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ends building a cognitivemodel via + — end","text":"obj model object class 'cognitivemodel' ... arguments (ignored)","code":""},{"path":"/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimates free parameters of a cognitvemodel generated via + — fit","title":"Estimates free parameters of a cognitvemodel generated via + — fit","text":"Estimates free parameters cognitvemodel generated via +","code":""},{"path":"/reference/fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimates free parameters of a cognitvemodel generated via + — fit","text":"","code":"fit(obj, ...)"},{"path":"/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimates free parameters of a cognitvemodel generated via + — fit","text":"obj model object class 'cognitivemodel' ... arguments passed cognitive model fitting","code":""},{"path":"/reference/fun.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a function to a cognitivemodel via + — fun","title":"Adds a function to a cognitivemodel via + — fun","text":"Adds function cognitivemodel via +","code":""},{"path":"/reference/fun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a function to a cognitivemodel via + — fun","text":"","code":"fun(obj, ...)"},{"path":"/reference/fun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a function to a cognitivemodel via + — fun","text":"obj model object class 'cognitivemodel' ... arguments (ignored)","code":""},{"path":"/reference/getCall.cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Call to a cognitive model object — getCall.cm","title":"Get the Call to a cognitive model object — getCall.cm","text":"Get Call cognitive model object","code":""},{"path":"/reference/getCall.cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Call to a cognitive model object — getCall.cm","text":"","code":"# S3 method for cm getCall(x, ...)"},{"path":"/reference/getCall.cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Call to a cognitive model object — getCall.cm","text":"x existing fit cognitive model function cm ... (ignored) arguments","code":""},{"path":"/reference/get_ev.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the expected value of gambles — get_ev","title":"Gets the expected value of gambles — get_ev","text":"Gets expected value gambles","code":""},{"path":"/reference/get_ev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the expected value of gambles — get_ev","text":"","code":"get_ev(x)"},{"path":"/reference/get_ev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the expected value of gambles — get_ev","text":"x risky gamble matrix: x, p, x, p options dimension 3","code":""},{"path":"/reference/get_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the probabilities of gambles — get_p","title":"Gets the probabilities of gambles — get_p","text":"Gets probabilities gambles","code":""},{"path":"/reference/get_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the probabilities of gambles — get_p","text":"","code":"get_p(x)"},{"path":"/reference/get_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the probabilities of gambles — get_p","text":"x risky gamble matrix: x, p, x, p options dimension 3","code":""},{"path":"/reference/get_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the variance of gambles — get_var","title":"Gets the variance of gambles — get_var","text":"Gets variance gambles","code":""},{"path":"/reference/get_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the variance of gambles — get_var","text":"","code":"get_var(x)"},{"path":"/reference/get_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the variance of gambles — get_var","text":"x risky gamble matrix: x, p, x, p options dimension 3","code":""},{"path":"/reference/get_x.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the outcomes of gambles — get_x","title":"Gets the outcomes of gambles — get_x","text":"Gets outcomes gambles","code":""},{"path":"/reference/get_x.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the outcomes of gambles — get_x","text":"","code":"get_x(x)"},{"path":"/reference/get_x.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the outcomes of gambles — get_x","text":"x risky gamble matrix: x, p, x, p options dimension 3","code":""},{"path":"/reference/gof.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Various Model Fit Measures — gof","title":"Computes Various Model Fit Measures — gof","text":"logLik(m) computes log likelihood cm object, SSE(m) computes sum squared errors, MSE(m) computes mean squared error.","code":""},{"path":"/reference/gof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Various Model Fit Measures — gof","text":"","code":"# S3 method for cm logLik(object, newdata = NULL, ...)  MSE(x)  RMSE.cm(x)  SSE(x, ...)  SSE(x)"},{"path":"/reference/gof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Various Model Fit Measures — gof","text":"... arguments (ignored) x cm object","code":""},{"path":"/reference/gof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes Various Model Fit Measures — gof","text":"number measuring goodness fit predictions observed data.","code":""},{"path":"/reference/gof.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes Various Model Fit Measures — gof","text":"model predicts several values error measures use first column predictions compute errors. example, predictions pr(x) pr(z), sum squared errors based data - pr(x).","code":""},{"path":[]},{"path":"/reference/gof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes Various Model Fit Measures — gof","text":"","code":"MSE(M)     # 0.1805 #> Error in MSE(M): object 'M' not found  D <- data.frame(x = 1, y = 1:1, z = 0:1) M <- bayes_beta(y ~ x + z, D, fix = \"start\") #> Error in bayes_beta(y ~ x + z, D, fix = \"start\"): could not find function \"bayes_beta\" # If you want, look at the predictions # predict(M)  SSE(M)     # 0.361 #> Error in SSE(M): object 'M' not found"},{"path":"/reference/hm1988.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"hm1988() generates Houston & McNamara's (1988) optimal model risk-sensitive foraging discrete choices.","code":""},{"path":"/reference/hm1988.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"","code":"hm1988(   formula,   trials,   states,   budget,   ntrials,   initstate = 0,   data = NULL,   choicerule = \"argmax\",   fix = list(),   options = NULL,   fitnessfun = NULL )"},{"path":"/reference/hm1988.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"formula formula, variables data modeled. example, y ~ x1 + p2 + x3 + p4 | x5 + p6 + x7 + p8 models response y function two stimuli features x1, p2, x3, p4 x5, p6, x7, p8, alternating outcomes x probabilities p (respectively). Lines | separate stimuli. trials variable data decision trial, can number, numeric vector, string, formula, \".\". Vectors must length nrow(data). \".\" model predicts possible trials states. states variable data states/accumulated resources, can number, numeric vector, string, formula, \".\". Vectors must length nrow(data). \".\" model predicts possible trials states. budget number; goal/requirement/critical state, matters terminal payout function. Can also numeric vector length nrow(data), right-side formula refers variable data. ntrials number; total number trials available. Can also numeric vector length nrow(data), right-side formula refers variable data. initstate (default 0) number; starting state first trial. Can also numeric vector length nrow(data), right-side formula refers variable data. data data frame, data modeled. choicerule string, choice rule. Allowed values, see  cm_choicerules(): \"none\" choice rule, \"softmax\" soft-maximum, \"luce\" Luce's axiom. fix (optional, choicerule softmax, epsilon) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names depend choicerule can tau, eps (see details - model parameters). list(tau = 6.16) sets parameter tau equal 6.16. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. fitnessfun (optional) function, terminal fitness function, needs two arguments, budget state. discount number, many initial trials use parameter fitting. ... arguments, ignored.","code":""},{"path":"/reference/hm1988.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/hm1988.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"Risk-sensitive foraging means , instance, four choices two risky lotteries four choices need accumulated least 12 points get reward. optimal solution choice problem relies dynamic programming. function creates possible future states given possible remaining trials, predicts optimal choice polica expected value chosing either option given certain state certain time horizon.","code":""},{"path":"/reference/hm1988.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"model free parameters. choicerule specified, can estimate 1 free parameter: choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":"/reference/hm1988.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"Houston, . ., & McNamara, J. M. (1988). framework functional analysis behaviour. Behavioural Brain Science, 11, 117-163. doi:10.1017/S0140525X00053061","code":""},{"path":[]},{"path":"/reference/hm1988.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/hm1988.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dynamic optimization model for risk-sensitive foraging problems in discrete time — hm1988","text":"","code":"## Make fake data ----------------------------------------------------- D <- data.frame(   x1 = 0, x2 = 1, x3 = 2,   px11 = 0.1, px12 = 0.8, px13 = 0.1,   px21 = 0.4, px22 = 0.2, px23 = 0.4,   s = rep(9:11, each = 4),   init = rep(9:11, each = 4), t = 4:1)  ## Setup the model -------------------------------------------------- M <- hm1988(~ x1+px11+x2+px12+x3+px13 | x1+px21+x2+px22+x3+px23,              trials = ~t, states = ~s, budget = 12, ntrials = 4,              initstate = ~init, data = D, choicerule = \"argmax\")  M                          # View model #> Optimal RSFT Model (Houston & McNamara, 1988) | choice rule: argmax #> Call: #> hm1988(formula = ~x1 + px11 + x2 + px12 + x3 + px13 | x1 + px21 +  ... #>  #>  #> --- #> Note:  No free parameters. No fixed parameter.  predict(M)                 # Predict choice probability of 1st option (arg-max) #>  [1] 0.5 0.0 1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 predict(M, type=\"values\")  # Predict expected values #>        x1px1  x1px2 #>  [1,] 0.0000 0.0000 #>  [2,] 0.4100 0.4400 #>  [3,] 0.8310 0.7440 #>  [4,] 0.9654 0.9276 #>  [5,] 0.1000 0.4000 #>  [6,] 0.8600 0.7400 #>  [7,] 0.9780 0.9420 #>  [8,] 0.9970 0.9910 #>  [9,] 0.9000 0.6000 #> [10,] 0.9900 0.9600 #> [11,] 0.9990 0.9960 #> [12,] 0.9999 0.9996"},{"path":"/reference/information.html","id":null,"dir":"Reference","previous_headings":"","what":"Information about a cognitive model and the data in it — information","title":"Information about a cognitive model and the data in it — information","text":"Get information cognitive model, example model m npar(m) gives number parameters model m coef(m) gives number free parameters model m nstim(m) gives number stimuli data supplied model m natt(m) gives number attributes stimulus nobs(m) gives number observations data model fitted ","code":""},{"path":"/reference/information.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information about a cognitive model and the data in it — information","text":"","code":"npar(object, ...)  # S3 method for cm npar(object, type = \"all\", ...)  nobs(object, ...)  # S3 method for cm nobs(object, ...)  nstim(object, ...)  # S3 method for cm nstim(object, ...)  natt(object, ...)  # S3 method for cm natt(object, ...)  # S3 method for cm coef(object, ...)"},{"path":"/reference/information.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information about a cognitive model and the data in it — information","text":"object object class cm, .e. cognitive model ... ignored type string: \"\" counts parameters, \"free\" counts free parameters, \"fix\" countes fixed parameters, \"constrained\" counts constrained parameters.","code":""},{"path":"/reference/information.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information about a cognitive model and the data in it — information","text":"","code":"## Create data D and amodel D <- data.frame(x = 1, y = 1, z = 1) model <- bayes_beta_d(y ~ x + z, D, fix = \"start\") ## Get information npar(model) # 3 parameter #> [1] 3 coef(model) # 0 free parameter #> NULL nstim(model) # 1 stimulus #> [1] 1 natt(model) # 2 attributes (x, z) of the stimulus #> [1] 2 nobs(model) # 1 observation in the data D #> [1] 1"},{"path":"/reference/lwei.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear-weighting model — lwei","title":"Linear-weighting model — lwei","text":"Linear-weighting model","code":""},{"path":"/reference/lwei.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear-weighting model — lwei","text":"","code":"lwei(   formula,   nopt,   nout,   ref,   fix = NULL,   data,   choicerule,   weighting = c(\"TK1992\"),   value = c(\"TK1992\") )"},{"path":"/reference/mahalanobis.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Mahalanobis Distance — mahalanobis","title":"Weighted Mahalanobis Distance — mahalanobis","text":"Weighted Mahalanobis Distance","code":""},{"path":"/reference/mahalanobis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Mahalanobis Distance — mahalanobis","text":"","code":"mahalanobis(x, y, s, w, q)"},{"path":"/reference/mahalanobis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Mahalanobis Distance — mahalanobis","text":"x numeric vector, feature values first object y Like x, feature values second object s Inverted variance-covariance matrix w numeric vector weights (model parameter) q exponent similarity function (model parameter)","code":""},{"path":"/reference/mahalanobis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted Mahalanobis Distance — mahalanobis","text":"","code":"# none"},{"path":"/reference/make_parspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Define parameter for cognitive models — make_parspace","title":"Define parameter for cognitive models — make_parspace","text":"make_parspace() makes n x 4 matrix parameter bounds, starting value, -effect value parameters","code":""},{"path":"/reference/make_parspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define parameter for cognitive models — make_parspace","text":"","code":"make_parspace(...)"},{"path":"/reference/make_parspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define parameter for cognitive models — make_parspace","text":"... Parameters ranges, e.g., make_parspace(theta = c(ub=-1, lb=1, init=0, na=0), gamma = c(0,2,1,NA)). See details examples. general schema per parameter named vector parametername = c(ub = #, lb = #, init = #, na = #). \"lb\" Lower limit, smallest allowed value \"ub\" Upper limit, highest allowed value \"start\" (optional) Initial value estimation parameters \"na\" (optional) Value parameter takes effect, can 'NA'","code":""},{"path":"/reference/make_parspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define parameter for cognitive models — make_parspace","text":"matrix many rows parameters, rownames parameter names, four columns lb, ub, init, na define lower limit, upper limit, initial value null-effect-value (optional) parameter.","code":""},{"path":"/reference/make_parspace.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define parameter for cognitive models — make_parspace","text":"\"na\" optional value parameter takes parameter effect. define parameter \\(\\alpha\\) \\(0 \\le \\alpha \\le 1\\) use one argument, alpha = c(0,1). define additional parameter \\(\\beta\\) \\(2 \\le \\beta \\le 9\\) use two arguments, alpha = c(0,1), beta = c(2,9), forth. can specify initial value parameter used fitting third element vectors.","code":""},{"path":"/reference/make_parspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define parameter for cognitive models — make_parspace","text":"","code":"## Define a parameter \"p\" that can range from 0-1 make_parspace(p = c(0,1)) #>   lb ub start na #> p  0  1   0.5 NA makeparspapce(p = c(lb=0, ub=2)) # the same #> Error in makeparspapce(p = c(lb = 0, ub = 2)): could not find function \"makeparspapce\"  # Note: # Initial value will be the mean of 0 and 1.   ## Define a parameter \"zeta\" from 0-5 ## and set the initial value to 2 make_parspace(zeta = c(lb=0, ub=5, init=2)) #>      lb ub start na #> zeta  0  5     2 NA make_parspace(zeta = c(0,5,2)) # the same #>      lb ub start na #> zeta  0  5     2 NA make_parspace(zeta = c(ub=5,lb=0,init=2)) #the same #> Error: Lower bound of parameter space cannot be greater than upper bound, but lb > ub for each of the parameters (lb > ub): #>   * zeta: 5 > 0 #>   -> Check parspace. Ensure the lb < ub, e.g. 'make_parspace(a = c(0, 1, 0.5))'.   ## Define one parameter \"expon\" from 0-2 with initial value 0.5 ## and a value of 1 making it have no effect make_parspace(expon = c(0,2,1,1)) #>       lb ub start na #> expon  0  2     1  1 make_parspace(expon = c(lb=0,ub=2,init=1,na=1)) #the same #>       lb ub start na #> expon  0  2     1  1   ## Define four parameter alpha, beta, gamma, delta make_parspace(alpha = c(lb=0,ub=1,init=0.5,na=0),                 beta = c(1,10,5,NA),                 gamma = c(lb=1,ub=2,init=0,na=1),                 delta = c(1,2,0)) #> Error in make_parspace(alpha = c(lb = 0, ub = 1, init = 0.5, na = 0),     beta = c(1, 10, 5, NA), gamma = c(lb = 1, ub = 2, init = 0,         na = 1), delta = c(1, 2, 0)): Initial value < lower limit for the parameter: [\"gamma\", \"delta\"]. Ensure \"start\" is > \"lb\"), e.g. make_parspace(a = c(0, 1, 0.5)).  ## Dynamically define new parameter \"gamma\" and \"delta\" ## with the same definition (ub, lb, init, na) def <- c(lb = 0, ub = 1, init = 0.5, na = 0) deflist <- list(\"gamma\" = def, \"delta\" = def) do.call(make_parspace, deflist) #>       lb ub start na #> gamma  0  1   0.5  0 #> delta  0  1   0.5  0"},{"path":"/reference/minkowski.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Minkowski Distance — minkowski","title":"Weighted Minkowski Distance — minkowski","text":"Weighted Minkowski Distance","code":""},{"path":"/reference/minkowski.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Minkowski Distance — minkowski","text":"","code":"minkowski(x, y, w, r, q)"},{"path":"/reference/minkowski.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Minkowski Distance — minkowski","text":"x numeric vector, feature values first object y Like x, feature values second object w numeric vector weights (model parameter) r exponent distance metic (model parameter) q exponent similarity function (model parameter)","code":""},{"path":"/reference/minkowski.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted Minkowski Distance — minkowski","text":"","code":"# none"},{"path":"/reference/nosofsky1989.html","id":null,"dir":"Reference","previous_headings":"","what":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"Data categorization four different conditions.","code":""},{"path":"/reference/nosofsky1989.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"object class \"data.frame\".#'","code":""},{"path":"/reference/nosofsky1989.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"Table 3 Figure 2 Nosofsky, R. M. (1989). tests exemplar-similarity approach relating identification categorization. Perception & Psychophysics, 45, 279–290. doi:10.3758/BF03204942","code":""},{"path":"/reference/nosofsky1989.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"condition. experimental condition (size, angle, criss, diag) angle. feature value angle feature size. feature value size feature N. often feature combination occured. obs_cat. often category 1 mode observed given feature combination. pobs. Probability category 1 mode observed given feature combination (obs_cat / N) true_cat. True category label feature combination (0 1)","code":""},{"path":"/reference/nosofsky1989.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"Nosofsky, R. M. (1989). tests exemplar-similarity approach relating identification categorization. Perception & Psychophysics, 45, 279–290. doi:10.3758/BF03204942","code":""},{"path":"/reference/nosofsky1989.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989","text":"","code":"data(nosofsky1989)"},{"path":"/reference/nosofsky1989long.html","id":null,"dir":"Reference","previous_headings":"","what":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"Data categorization four different conditions.","code":""},{"path":"/reference/nosofsky1989long.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"object class \"data.frame\".#'","code":""},{"path":"/reference/nosofsky1989long.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"Table 3 Figure 2 Nosofsky, R. M. (1989). tests exemplar-similarity approach relating identification categorization. Perception & Psychophysics, 45, 279–290. doi:10.3758/BF03204942","code":""},{"path":"/reference/nosofsky1989long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"condition. experimental condition (size, angle, criss, diag) angle. feature value angle feature size. feature value size feature response. category selected? true_cat. True category label feature combination (0 1)","code":""},{"path":"/reference/nosofsky1989long.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"Nosofsky, R. M. (1989). tests exemplar-similarity approach relating identification categorization. Perception & Psychophysics, 45, 279–290. doi:10.3758/BF03204942","code":""},{"path":"/reference/nosofsky1989long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test data for fitting the Exemplar-based categorization model — nosofsky1989long","text":"","code":"data(nosofsky1989long)"},{"path":"/reference/npar.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Parameters, Attributes, and Stimuli — npar","title":"Number of Parameters, Attributes, and Stimuli — npar","text":"npar(m) counts parameters cm, nstim(m) counts stimuli, natt(m) counts attributes stimulus, nobs(m) counts observations data model.","code":""},{"path":"/reference/npar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Parameters, Attributes, and Stimuli — npar","text":"","code":"npar(x)  # S3 method for cm npar(x, type = \"all\", ...)"},{"path":"/reference/npar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Parameters, Attributes, and Stimuli — npar","text":"x model object ... ignored type string: \"\" counts parameters, \"free\" counts free parameters, \"fix\" countes fixed parameters, \"constrained\" counts constrained parameters.","code":""},{"path":"/reference/npar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Parameters, Attributes, and Stimuli — npar","text":"","code":"D <- data.frame(x = 1, y = 1, z = 1) M <- bayes_beta(y ~ x + z, D, fix = \"start\") #> Error in bayes_beta(y ~ x + z, D, fix = \"start\"): could not find function \"bayes_beta\" npar(M) # 3 #> Error in npar(M): object 'M' not found npar(M) #> Error in npar(M): object 'M' not found"},{"path":"/reference/parspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the paramter space of a cognitive model — parspace","title":"Show the paramter space of a cognitive model — parspace","text":"parspace(m) shows parameter names, upper lower bounds parameters cognitive model stored m.","code":""},{"path":"/reference/parspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the paramter space of a cognitive model — parspace","text":"","code":"parspace(x, ...)  # S3 method for cm parspace(x, ...)  # S3 method for character parspace(x, ...)"},{"path":"/reference/parspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the paramter space of a cognitive model — parspace","text":"x model object class cm ... arguments (ignored)","code":""},{"path":"/reference/parspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the paramter space of a cognitive model — parspace","text":"","code":"D <- data.frame(x = 1, y = 1, z = 1) M <- bayes_beta(y ~ x + z, D, fix = \"start\") #> Error in bayes_beta(y ~ x + z, D, fix = \"start\"): could not find function \"bayes_beta\" parspace(M)    # view the parspace #> Error in parspace(M): object 'M' not found"},{"path":"/reference/plus-.cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a component to a cognitivemodel via + — +.cm","title":"Adds a component to a cognitivemodel via + — +.cm","text":"Adds component cognitivemodel via +","code":""},{"path":"/reference/plus-.cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a component to a cognitivemodel via + — +.cm","text":"","code":"# S3 method for cm +(e1, e2)"},{"path":"/reference/plus-.cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a component to a cognitivemodel via + — +.cm","text":"e1 cognitive model component, see examples e2 model component, see examples","code":""},{"path":"/reference/predict.cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions from Cognitive Models (class cm) — predict.cm","title":"Predictions from Cognitive Models (class cm) — predict.cm","text":"Predictions Cognitive Models (class cm)","code":""},{"path":"/reference/predict.cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions from Cognitive Models (class cm) — predict.cm","text":"","code":"# S3 method for cm predict(object, newdata = NULL, ..., type = \"response\")"},{"path":"/reference/predict.cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions from Cognitive Models (class cm) — predict.cm","text":"object cognitive model object class 'cm' newdata data.frame new data predict ... Additional cognitive models type string, predict, usually \"response\", values may possible, see help pages model use.","code":""},{"path":"/reference/predict.cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions from Cognitive Models (class cm) — predict.cm","text":"vector matrix predictions, multiple models supplied using ..., returns list containing predictions model","code":""},{"path":"/reference/print.csm_constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints the constraints of a cogscimodel object nicely — print.csm_constraint","title":"Prints the constraints of a cogscimodel object nicely — print.csm_constraint","text":"NULL constraints","code":""},{"path":"/reference/print.csm_constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints the constraints of a cogscimodel object nicely — print.csm_constraint","text":"","code":"# S3 method for csm_constraint print(x, ..., latex = FALSE)"},{"path":"/reference/print.csm_constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints the constraints of a cogscimodel object nicely — print.csm_constraint","text":"latex (optional) TRUE formats LaTeX documents","code":""},{"path":"/reference/rsenvironment.html","id":null,"dir":"Reference","previous_headings":"","what":"Class for risk-sensitive foraging environments — rsenvironment","title":"Class for risk-sensitive foraging environments — rsenvironment","text":"Class risk-sensitive foraging environments","code":""},{"path":"/reference/rsenvironment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class for risk-sensitive foraging environments — rsenvironment","text":"","code":"rsenvironment(   budget,   ...,   n.trials,   initial.state,   terminal.fitness = function(state, budget) {     as.numeric(state >= budget) } )"},{"path":"/reference/rsenvironment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class for risk-sensitive foraging environments — rsenvironment","text":"budget Numeric, minimum requirement. ... Numeric matrix (n x 2) probabilities column one outcomes columnn 2. n.trials Numeric, number trials. initial.state Numeric, starting state. terminal.fitness Function specifies terminal reward (get end n.trials), defaults \"get zero budget 1 otherwise\". See details.","code":""},{"path":"/reference/rsenvironment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class for risk-sensitive foraging environments — rsenvironment","text":"argument terminal.fitness must function exactly two arguments budget state, returns budget state terminal reward.","code":""},{"path":"/reference/shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Shifting Cognitive Model — shift","title":"Shifting Cognitive Model — shift","text":"Fits model shifts time one value another value, change point time free parameter shift_d() fits change point model discrete responses.","code":""},{"path":"/reference/shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shifting Cognitive Model — shift","text":"","code":"shift_d(formula, data, time, fix = NULL, options, discount = 0, ...)"},{"path":"/reference/shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shifting Cognitive Model — shift","text":"formula formula, variables data modeled. example, y ~ x1 + x2 models response y function shifting x1 x2. data data frame, data modeled. time (optional) Variable decision time trial across shift occurs; can numeric vector, string, formula. missing set range 1 number rows data. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names c (see details - model parameters). list(c = 1.85) sets parameter c equal 1.85. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. discount (optional) number, e.g. 10 ignores first ten data rows fitting parameters calculating goodness fits ... arguments, ignored.","code":""},{"path":"/reference/shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shifting Cognitive Model — shift","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/shift.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Shifting Cognitive Model — shift","text":"model models shift two input values time.","code":""},{"path":"/reference/shift.html","id":"parameter-space","dir":"Reference","previous_headings":"","what":"Parameter Space","title":"Shifting Cognitive Model — shift","text":"model 1 free parameter: c change point shift occurs time Additoinal parameters shift_c(): choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":[]},{"path":"/reference/shift.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shifting Cognitive Model — shift","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shifting Cognitive Model — shift","text":"","code":"## Make fake data ----------------------------------------------------- D <- data.frame(a = rep(0L,4), b = 1L, y = c(0,0,1,1)) M <- shift_d(~ a + b, D, fix = c(c=1.5)) predict(M) #> [1] 4.539787e-05 9.999546e-01 1.000000e+00 1.000000e+00"},{"path":"/reference/shortfall.html","id":null,"dir":"Reference","previous_headings":"","what":"Shortfall Risky Choice Model — shortfall","title":"Shortfall Risky Choice Model — shortfall","text":"Fits shortfall model risky choices judgments (Andraszewicz, 2014). shortfall_d() fits shortfall model discrete responses (select option). shortfall_c() fits shortfall model continuous responses (judge options).","code":""},{"path":"/reference/shortfall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shortfall Risky Choice Model — shortfall","text":"","code":"shortfall_d(formula, asp, data, choicerule, fix = list(), options = NULL)  shortfall_c(formula, asp, data, fix = list(), options = NULL)"},{"path":"/reference/shortfall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shortfall Risky Choice Model — shortfall","text":"formula formula, variables data modeled. example, y ~ x1 + p2 + x3 + p4 | x5 + p6 + x7 + p8 models response y function two stimuli features x1, p2, x3, p4 x5, p6, x7, p8, alternating outcomes x probabilities p (respectively). Lines | separate stimuli. asp formula string, variable data aspiration level. example, ~ x9 \"x9\". Can stimulus-specific: example ~ x9 | x10 sets x9, x10 aspiration levels 1. 2. stimulus (respectively). data data frame, data modeled. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names beta, delta (see details - model parameters). list(beta = 3.09) sets parameter beta equal 3.09. list(beta = \"delta\") sets parameter beta equal parameter delta (estimates delta). list(delta = \"beta\", beta = 3.09) sets parameter delta equal parameter beta sets beta equal 3.09 (estimates none two). list(beta = NA) omits parameter beta, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. discount number, many initial trials use parameter fitting. ... arguments, ignored.","code":""},{"path":"/reference/shortfall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shortfall Risky Choice Model — shortfall","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/shortfall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Shortfall Risky Choice Model — shortfall","text":"model trades expected value risky option \\(\\beta\\)-weighted measure risk option. Risk defined chance falling short \\(\\delta\\)-weighted aspiration level (see Andraszewicz, 2014). Model inputs risky options aspiration level. subjective value \\(v\\) option \\(o\\) given parameters \\(\\delta, \\beta\\) modeled $$v(o) = EV(o) - \\beta R(o)$$ $$R(o) = \\sum_i ( p_i ( max [ \\delta asp_{o} - x_{o,} , 0 ] )$$.","code":""},{"path":"/reference/shortfall.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Shortfall Risky Choice Model — shortfall","text":"beta: weight risk, risk aversion (\\(0 \\le \\beta \\le 10\\)). delta: weight aspiration level (\\(0 \\le \\delta \\le 1\\)). shortfall_d(): choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":"/reference/shortfall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Shortfall Risky Choice Model — shortfall","text":"Andraszewicz, S. (2014). Quantitative analysis risky decision making economic environments \\(Doctoral dissertation, University Basel\\). doi:10.5451/unibas-006268585","code":""},{"path":[]},{"path":"/reference/shortfall.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shortfall Risky Choice Model — shortfall","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/shortfall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shortfall Risky Choice Model — shortfall","text":"","code":"# Make some data ----------------------------------- dt <- data.frame(    x1 = rep(1,3), x2 = rep(2,3), px = rep(.5,3),     y1 = 0:2, y2 = rep(3,3), py = rep(.5,3),    aspiration = rep(1,3), choice = c(1,1,0))  # Make model ---------------------------------------- # 1. Continuous model - normal log likelihood m <- shortfall_c(    formula = choice ~ x1 + px + x2,    asp = \"aspiration\",    data = dt) #> Fitting free parameters [beta, delta, sigma] by maximizing loglikelihood (normal pdf) with grid, solnp.  m            # view model #> Shortfall | choice rule: none #> Call: #> shortfall_c(formula = choice ~ x1 + px + x2, asp = \"aspiration\",  ... #>  #> Free parameters: estimates  #>  beta  delta  sigma   #> 0.100  0.073  0.957   #>  #>  #> --- #> Note:  No fixed parameter.  predict(m)   # predict values/ratings #> [1] 1.5 1.5 1.5 parspace(m)  # view parameter space #>  #> Parameter space of the cognitive model 'Shortfall': #>               lb         ub      start         na #> beta   0.0000000 10.0000000  1.0000000  0.0000000 #> delta  0.0000000  1.0000000  0.5000000  1.0000000 #> sigma  0.0000001  1.0000000  0.5000001         NA #> --- #> Note. lb = lower bound, ub = upper bound, start = start value.  # 2. Discrete model - binomial log likelihood m <- shortfall_d(    formula = choice ~ x1 + px + x2 | y1 + py + y2,    asp = \"aspiration\",    data = dt,    choicerule = \"softmax\") #> Fitting free parameters [beta, delta, tau] by maximizing loglikelihood (binomial pdf) with grid, solnp.  m            # View model #> Shortfall | choice rule: softmax #> Call: #> shortfall_d(formula = choice ~ x1 + px + x2 | y1 + py + y2, asp = \"aspiration\",  ... #>  #> Free parameters: estimates  #>  beta  delta    tau   #>    10      1      1   #>  #>  #> --- #> Note:  No fixed parameter.  predict(m)   # predict choice, Pr(select \"x\") #> [1] 0.9925915 0.3799480 0.2729835 parspace(m)  # View parameter space #>  #> Parameter space of the cognitive model 'Shortfall': #>           lb     ub  start     na #> beta   0.000 10.000  1.000  0.000 #> delta  0.000  1.000  0.500  1.000 #> tau    0.001 10.000  0.500     NA #> --- #> Note. lb = lower bound, ub = upper bound, start = start value."},{"path":"/reference/shortfalltest.html","id":null,"dir":"Reference","previous_headings":"","what":"Test data for fitting the Shortfall model — shortfalltest","title":"Test data for fitting the Shortfall model — shortfalltest","text":"Data risky choices test parameter estimation method shortfall model.","code":""},{"path":"/reference/shortfalltest.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test data for fitting the Shortfall model — shortfalltest","text":"object class \"data.table\"; see fread.","code":""},{"path":"/reference/shortfalltest.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Test data for fitting the Shortfall model — shortfalltest","text":"Andraszewicz, S. (2014). Quantitative analysis risky decision making economic environments (Doctoral dissertation, University_of_Basel). doi:10.5451/unibas-006268585","code":""},{"path":"/reference/shortfalltest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test data for fitting the Shortfall model — shortfalltest","text":"Andraszewicz, S. (2014). Quantitative analysis risky decision making economic environments (Doctoral dissertation, University_of_Basel). doi:10.5451/unibas-006268585","code":""},{"path":"/reference/shortfalltest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test data for fitting the Shortfall model — shortfalltest","text":"","code":"data(shortfalltest)"},{"path":"/reference/shortfall_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Predictions in the Shortfall Model — shortfall_cpp","title":"Computes Predictions in the Shortfall Model — shortfall_cpp","text":"Computes Predictions Shortfall Model","code":""},{"path":"/reference/shortfall_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Predictions in the Shortfall Model — shortfall_cpp","text":"","code":"shortfall_cpp(x, p, a, beta, delta)"},{"path":"/reference/shortfall_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Predictions in the Shortfall Model — shortfall_cpp","text":"x Numeric matrix, outcomes p Numeric matrix, probabilities Numeric vector, aspiration levels beta Model parameter delta Model parameter","code":""},{"path":"/reference/summary.cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizes cognitive models — summary.cm","title":"Summarizes cognitive models — summary.cm","text":"Summarizes cognitive models","code":""},{"path":"/reference/summary.cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizes cognitive models — summary.cm","text":"","code":"# S3 method for cm summary(object, ...)"},{"path":"/reference/summary.cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizes cognitive models — summary.cm","text":"object cognitive model (.e., object class cm) ... ignored","code":""},{"path":"/reference/threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Threshold Model — threshold","title":"Threshold Model — threshold","text":"treshold() fits threshold model threshold free parameter. treshold_c() models continuous responses form distance threshold treshold_d() models discrete choices given distance threshold","code":""},{"path":"/reference/threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threshold Model — threshold","text":"","code":"threshold(   formula,   data,   fix = list(),   choicerule = NULL,   mode,   discount = 0L,   options = list(),   ... )  threshold_c(   formula,   data,   fix = list(),   choicerule = NULL,   discount = 0,   options = list(),   ... )  threshold_d(   formula,   data,   fix = list(),   choicerule = \"softmax\",   discount = 0,   options = list(),   ... )"},{"path":"/reference/threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threshold Model — threshold","text":"formula formula, variables data modeled. example, y ~ x1 models response y function one stimulus value x1. data data frame, data modeled. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names nu (see details - model parameters). list(nu = 0.62) sets parameter nu equal 0.62. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. discount number, many initial trials use parameter fitting. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. ... arguments, ignored.","code":""},{"path":"/reference/threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Threshold Model — threshold","text":"model class \"treshold\". Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/threshold.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Threshold Model — threshold","text":"nu: threshold.","code":""},{"path":"/reference/threshold.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Threshold Model — threshold","text":"Given formula y ~ model predicts y = 1 >= nu y = 0 < nu","code":""},{"path":[]},{"path":"/reference/threshold.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Threshold Model — threshold","text":"Jana B. Jarecki, jj@janajarecki.com Jana B. Jarecki","code":""},{"path":"/reference/threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Threshold Model — threshold","text":"","code":"D <- data.frame(        y = rep(0:1, each=5),        a = 1:10)  M <- threshold_c(y ~ a, D, fix=\"start\")        # fixed par. to start values predict(M)                                     # predict dist. to threshold #>  [1] -4.5 -3.5 -2.5 -1.5 -0.5  0.5  1.5  2.5  3.5  4.5 anova(M)                                       # anova-like table #> Sum Sq. Table #>  N Par Sum Sq Mean Sq #>      0   62.5    6.25 summary(M)                                     # summarize #>  #> Model: #>   with no choice rule #> Call: #> y ~ a #>  #> No Free Parameters #>  #> Fit Measures: #> MSE: 6.2, LL: -127, AIC: 255, BIC: 255 #>   M <- threshold_d(y ~ a, D, fix=\"start\")        # fixed par. to start values predict(M)                                     # predict dist. to threshold #>  [1] 2.061154e-09 1.125352e-07 6.144175e-06 3.353501e-04 1.798621e-02 #>  [6] 5.000000e-01 9.820138e-01 9.996646e-01 9.999939e-01 9.999999e-01 anova(M)                                       # anova-like table #> Sum Sq. Table #>  N Par  Sum Sq  Mean Sq #>      0 0.25065 0.025065 summary(M)                                     # summarize #>  #> Model: #>   with no choice rule #> Call: #> y ~ a #>  #> No Free Parameters #>  #> Fit Measures: #> MSE: 0.025, LL: -0.73, AIC: 1.5, BIC: 1.5 #>  M$MSE()                                        # mean-squared error    #> [1] 0.02506472  ### Binary response given a threshold # -------------------------------------------- M <- threshold(y ~ a, D, fix=\"start\", choicerule = \"softmax\") #> Error in match.arg(mode, c(\"continuous\", \"discrete\")): argument \"mode\" is missing, with no default predict(M)                       #  --\"--  maximum posterior #>  [1] 2.061154e-09 1.125352e-07 6.144175e-06 3.353501e-04 1.798621e-02 #>  [6] 5.000000e-01 9.820138e-01 9.996646e-01 9.999939e-01 9.999999e-01 anova(M)                                       # anova-like table #> Sum Sq. Table #>  N Par  Sum Sq  Mean Sq #>      0 0.25065 0.025065 summary(M)                                     # summarize #>  #> Model: #>   with no choice rule #> Call: #> y ~ a #>  #> No Free Parameters #>  #> Fit Measures: #> MSE: 0.025, LL: -0.73, AIC: 1.5, BIC: 1.5 #>  M$MSE()                                        # mean-squared error     #> [1] 0.02506472   ### Parameter specification and fitting ---------------------------------------- # Use a response variable, y, to which we fit parameter threshold(y ~ a, D, fix = \"start\", \"softmax\")     # \"start\" fixes all par., #> Error in match.arg(mode, c(\"continuous\", \"discrete\")): argument \"mode\" is missing, with no default                                                   # and fits none  threshold(y ~ a , D, list(nu=2), \"softmax\")       # fix threshold nu to 2 #> Error in match.arg(mode, c(\"continuous\", \"discrete\")): argument \"mode\" is missing, with no default threshold(y ~ a, D, list(tau=0.5), \"softmax\")     # fix soft-max tau to 1    #> Error in match.arg(mode, c(\"continuous\", \"discrete\")): argument \"mode\" is missing, with no default threshold(y ~ a, D, choicerule = \"softmax\")       # nu and tau free param    #> Error in match.arg(mode, c(\"continuous\", \"discrete\")): argument \"mode\" is missing, with no default"},{"path":"/reference/tversky1992ex.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data with two risky gambles — tversky1992ex","title":"Example data with two risky gambles — tversky1992ex","text":"Data two example risky choices two gambles","code":""},{"path":"/reference/tversky1992ex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data with two risky gambles — tversky1992ex","text":"object class data.frame","code":""},{"path":"/reference/tversky1992ex.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example data with two risky gambles — tversky1992ex","text":"Tversky, ., & Kahneman, D. (1992). Advances prospect theory: Cumulative representation uncertainty. Journal Risk Uncertainty, 5(4), 297–323. doi10.1007/BF00122574","code":""},{"path":"/reference/tversky1992ex.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Example data with two risky gambles — tversky1992ex","text":"Tversky, ., & Kahneman, D. (1992). Advances prospect theory: Cumulative representation uncertainty. Journal Risk Uncertainty, 5(4), 297–323. doi10.1007/BF00122574","code":""},{"path":"/reference/tversky1992ex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example data with two risky gambles — tversky1992ex","text":"","code":"data(tversky1992ex)"},{"path":"/reference/utility.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility Function Models — utility","title":"Utility Function Models — utility","text":"Fits utility models. utility_pow_c() fits power utility continuous responses. utility_pow_d() fits power utility discrete respoonses.","code":""},{"path":"/reference/utility.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility Function Models — utility","text":"","code":"utility_pow_d(   formula,   data,   choicerule,   fix = list(),   discount = 0,   options = list(),   ... )  utility_pow_c(formula, data, fix = list(), discount = 0, options = list(), ...)"},{"path":"/reference/utility.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility Function Models — utility","text":"formula formula, variables data modeled. example, y ~ x1 models response y function one stimulus value x1. data data frame, data modeled. choicerule string, choice rule. Allowed values, see  cm_choicerules(): \"none\" choice rule, \"softmax\" soft-maximum, \"luce\" Luce's axiom. fix (optional) list parameter-value pairs fixed parameters. missing free parameters estimated. set \"start\" parameters fixed start values. Model parameter names rp, rn (see details - model parameters). list(rp = 5.40) sets parameter rp equal 5.40. list(rp = \"rn\") sets parameter rp equal parameter rn (estimates rn). list(rn = \"rp\", rp = 5.40) sets parameter rn equal parameter rp sets rp equal 5.40 (estimates none two). list(rp = NA) omits parameter rp, possible. \"start\" sets parameters equal initial values (estimates none). Useful building first test model. discount number, many initial trials use parameter fitting. options (optional) list, list entries change modeling procedure. example, list(lb = c(k=0)) changes lower bound parameter k 0, list(fit_measure = \"mse\") changes goodness fit measure parameter estimation mean-squared error,  options, see cm_options. ... arguments, ignored.","code":""},{"path":"/reference/utility.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility Function Models — utility","text":"Returns cognitive model object, object class cm. model, assigned m, can summarized summary(m) anova(m). parameter space can viewed using pa. rspace(m), constraints can viewed using constraints(m).","code":""},{"path":"/reference/utility.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Utility Function Models — utility","text":"power utility \\(U(x)\\) positive inputs, \\(x > 0\\), \\(x^r\\) \\(r > 0\\), \\(log(x)\\) \\(r = 0\\), \\(-x^r\\) \\(r < 0\\). power utility negative inputs \\(x\\) \\(-U(-x)\\) separate exponent r (Wakker, 2008). fit power utility one single exponent positive negative x, set fix = list(rp = \"rn\"), recommended mixed input.","code":""},{"path":"/reference/utility.html","id":"model-parameters","dir":"Reference","previous_headings":"","what":"Model Parameters","title":"Utility Function Models — utility","text":"model 1 3 free parameters, depending model data (see npar()): rp power utility exponent positive data \\(x \\ge\\) 0 (omitted \\(x <\\) 0). rn exponent negative data \\(x < 0\\) (omitted \\(x \\ge\\) 0). utility_pow_c(): sigma standard deviation normally-distributed loglikelihood responses. utility_pow_d(): choicerule = \"softmax\": tau  temperature choice softness, higher values cause equiprobable choices. choicerule = \"epsilon\": eps error proportion, higher values cause errors maximizing.","code":""},{"path":"/reference/utility.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Utility Function Models — utility","text":"Wakker, P. P. (2008). Explaining characteristics power (CRRA) utility family. Health Economics, 17(12), 1329-1344. doi:10.1002/hec.1331 Tversky, . (1967). Utility theory additivity analysis risky choices. Journal Experimental Psychology, 75(1), 27-36. doi:10.1037/h0024915","code":""},{"path":[]},{"path":"/reference/utility.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Utility Function Models — utility","text":"Jana B. Jarecki, jj@janajarecki.com","code":""},{"path":"/reference/utility.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility Function Models — utility","text":"","code":"#  No examples yet"},{"path":"/reference/varG.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance of probabilistically-described gambles (without N-1 correction) — varG","title":"Variance of probabilistically-described gambles (without N-1 correction) — varG","text":"Variance probabilistically-described gambles (without N-1 correction)","code":""},{"path":"/reference/varG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance of probabilistically-described gambles (without N-1 correction) — varG","text":"","code":"varG(p, x)"},{"path":"/reference/varG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance of probabilistically-described gambles (without N-1 correction) — varG","text":"p numeric vector matrix, probabilities. x numeric vector matrix, outcomes, length x.","code":""},{"path":"/reference/varG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance of probabilistically-described gambles (without N-1 correction) — varG","text":"variance gamble (input matrix) gambles","code":""},{"path":"/reference/varG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance of probabilistically-described gambles (without N-1 correction) — varG","text":"","code":"# Variance of the gamble 0 with 10% otherwise 10:  varG(p = c(.9,.1), x = c(0,10)) #> [1] 9"},{"path":"/news/index.html","id":"cognitivemodels-0012","dir":"Changelog","previous_headings":"","what":"cognitivemodels 0.0.12","title":"cognitivemodels 0.0.12","text":"Bugfixes Fixed bug fitting parameter cognitivemodels `+``functionality","code":""},{"path":"/news/index.html","id":"cognitivemodels-0010","dir":"Changelog","previous_headings":"","what":"cognitivemodels 0.0.10","title":"cognitivemodels 0.0.10","text":"Minor bugfixes","code":""},{"path":"/news/index.html","id":"cognitivemodels-0010-1","dir":"Changelog","previous_headings":"","what":"cognitivemodels 0.0.10","title":"cognitivemodels 0.0.10","text":"New features Added optional argument prior_sum Bayesian learning models set control sum constraints prior (hyper-)parameter, see ?bayes Added new model shift_c() models change point time shifting two values two predictions. See ?shift cpt() now allows weighting = NA value = NA arguments, leads probability weighting (treating probabilities ) subjective value transformation (treating outcomes ) model, respectively, see ?cpt Potentially breaking predict.cm changed order arguments argument newdata second position comply predict.glm methods Bugfixes Fixed bugs ROI optimization Fixed bug add_constraints() cognitivemodel lego variant Made dropping choicerule error warning easier understand. Declared solvers() depreciated warning, now use cm_solvers() show optimization solvers.","code":""},{"path":"/news/index.html","id":"cognitivemodels-009","dir":"Changelog","previous_headings":"","what":"cognitivemodels 0.0.9","title":"cognitivemodels 0.0.9","text":"Added NEWS.md file track changes package.","code":""}]
